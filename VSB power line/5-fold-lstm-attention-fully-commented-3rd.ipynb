{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e154a47bf09b8770980486e87786317a1b3038e1"
   },
   "source": [
    "### Meeting a Sayed Athar's request, I'm using the Kernel altered by Khoi Nguyen to explain how the whole code works.\n",
    "### If any part is not clear, please comment.  \n",
    "### Please upvote if it was helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq # Used to read the data\n",
    "import os \n",
    "import numpy as np\n",
    "from keras.layers import * # Keras is the most friendly Neural Network library, this Kernel use a lot of layers classes\n",
    "from keras.models import Model\n",
    "from tqdm import tqdm # Processing time measurement\n",
    "from sklearn.model_selection import train_test_split \n",
    "from keras import backend as K # The backend give us access to tensorflow operations and allow us to create the Attention class\n",
    "from keras import optimizers # Allow us to access the Adam class to modify some parameters\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold # Used to use Kfold to train our model\n",
    "from keras.callbacks import * # This object helps the model to train in a smarter way, avoiding overfitting\n",
    "import numpy.fft as fft\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "6e6379386e44afc69bee8895a52da22199e888fb"
   },
   "outputs": [],
   "source": [
    "# select how many folds will be created\n",
    "N_SPLITS = 5\n",
    "# it is just a constant with the measurements data size\n",
    "sample_size = 800000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "c3340ee96becb5ca8f075d9c44b7df383ddba5ee"
   },
   "outputs": [],
   "source": [
    "# It is the official metric used in this competition\n",
    "# below is the declaration of a function used inside the keras model, calculation with K (keras backend / thensorflow)\n",
    "def matthews_correlation(y_true, y_pred):\n",
    "    '''Calculates the Matthews correlation coefficient measure for quality\n",
    "    of binary classification problems.\n",
    "    '''\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "8df6356f6e4d36079961192e5751e455e6a900dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.1\n"
     ]
    }
   ],
   "source": [
    "y_true = K.variable([[0,0,0],[1,1,1],[1,0,1]])\n",
    "y_pred = K.variable([[1,0,0],[0,0,1],[1,1,1]])\n",
    "y_true2 = K.variable([0,0,0,1,1,1,1,0,1])\n",
    "y_pred2 = K.variable([1,0,0,0,0,1,1,1,1])\n",
    "\n",
    "print(K.eval(matthews_correlation(y_true, y_pred)),K.eval(matthews_correlation(y_true2, y_pred2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "eda7ea366117d1ce8e5fce69e5bba333821d8b48"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/suicaokhoailang/lstm-attention-baseline-0-652-lb\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_measurement</th>\n",
       "      <th>phase</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      signal_id  target\n",
       "id_measurement phase                   \n",
       "0              0              0       0\n",
       "               1              1       0\n",
       "               2              2       0\n",
       "1              0              3       1\n",
       "               1              4       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just load train data\n",
    "df_train = pd.read_csv('../input/metadata_train.csv')\n",
    "# set index, it makes the data access much faster\n",
    "df_train = df_train.set_index(['id_measurement', 'phase'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "9b56bdb5d575fca4b26868a9979e9e87b44223f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_measurement</th>\n",
       "      <th>phase</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2902</th>\n",
       "      <th>1</th>\n",
       "      <td>8707</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2903</th>\n",
       "      <th>0</th>\n",
       "      <td>8709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8710</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8711</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      signal_id  target\n",
       "id_measurement phase                   \n",
       "2902           1           8707       0\n",
       "               2           8708       0\n",
       "2903           0           8709       0\n",
       "               1           8710       0\n",
       "               2           8711       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "26df6c7fbfecd537404866faec13d1238ae3ebc6"
   },
   "outputs": [],
   "source": [
    "# in other notebook I have extracted the min and max values from the train data, the measurements\n",
    "max_num = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "300a2d2ee4a7b3ac55a0a69dff3abd531e54e1c9"
   },
   "outputs": [],
   "source": [
    "n_dim=160\n",
    "w = pywt.Wavelet('coif5')\n",
    "nl=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "c6137bbbe75c3a1509a5f98e08805dbbd492aa37"
   },
   "outputs": [],
   "source": [
    "# This is one of the most important peace of code of this Kernel\n",
    "# Any power line contain 3 phases of 800000 measurements, or 2.4 millions data \n",
    "# It would be praticaly impossible to build a NN with an input of that size\n",
    "# The ideia here is to reduce it each phase to a matrix of <n_dim> bins by n features\n",
    "# Each bean is a set of 5000 measurements (800000 / 160), so the features are extracted from this 5000 chunk data.\n",
    "def transform_ts(ts, n_dim=n_dim, min_max=(-1,1)):\n",
    "    # convert data into -1 to 1\n",
    "    # ts /= 128.0\n",
    "    # bucket or chunk size, 5000 in this case (800000 / 160)\n",
    "    bucket_size = int(sample_size / n_dim)\n",
    "    # new_ts will be the container of the new data\n",
    "    new_ts = []\n",
    "    # this for iteract any chunk/bucket until reach the whole sample_size (800000)\n",
    "    \n",
    "    '''some of features I added'''\n",
    "#     plt.plot(ts)\n",
    "#     plt.plot(fzfit)\n",
    "#     new_ts = np.append(new_ts,[phi])\n",
    "#     new_ts = np.append(new_ts,percentil_fz)\n",
    "    \n",
    "    #print(new_ts)\n",
    "    \n",
    "    for i in range(0, sample_size, bucket_size):\n",
    "        # cut each bucket to ts_range\n",
    "        \n",
    "        ts_range = ts[i:i + bucket_size]\n",
    "        cwt = pywt.wavedec(ts_range, w, level=nl)\n",
    "        # calculate each feature\n",
    "        nj=[]\n",
    "        for j in range(nl+1):\n",
    "            mean = cwt[j].mean()\n",
    "            std = cwt[j].std()\n",
    "            percentil = np.percentile(cwt[j], [0, 1, 25, 50, 75, 99, 100]) \n",
    "            nj += [mean,std]\n",
    "            nj += list(percentil)\n",
    "        new_ts += [nj]\n",
    "    #print(np.asarray(new_ts).shape)\n",
    "    return np.asarray(new_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "4d1d754af05c87a6b5f8f2e27b508014c67e51a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -88.53084818,    2.32666522,  -94.73027722, ...,    0.27988937,\n",
       "           0.97479176,    3.54929324],\n",
       "       [ -83.39593658,    2.11978358,  -89.6592986 , ...,    0.31641296,\n",
       "           1.21128039,   10.03361081],\n",
       "       [ -78.37265849,    2.41833206,  -82.37566106, ...,    0.30436853,\n",
       "           0.96117711,    4.83131757],\n",
       "       ...,\n",
       "       [-100.3101889 ,    1.69457386, -103.99902433, ...,    0.28730831,\n",
       "           1.0557028 ,    1.95649691],\n",
       "       [ -96.94308645,    2.20236516, -102.53004156, ...,    0.28320539,\n",
       "           1.00724049,    5.10392475],\n",
       "       [ -91.97224005,    2.88215366,  -97.11812291, ...,    0.30026385,\n",
       "           1.09877933,    9.16013838]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col=\"3\"\n",
    "ts=pq.read_pandas('../input/train.parquet', columns=[col]).to_pandas()[col]\n",
    "transform_ts(ts, n_dim=n_dim, min_max=(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "7460e718a605803f1d9e4fbec61750a0deb02a47"
   },
   "outputs": [],
   "source": [
    "# this function take a piece of data and convert using transform_ts(), but it does to each of the 3 phases\n",
    "# if we would try to do in one time, could exceed the RAM Memmory\n",
    "def prep_data(df,IDs,path):\n",
    "    start, end = IDs[0], IDs[-1]\n",
    "    # load a piece of data from file\n",
    "    praq = pq.read_pandas(path, columns=[str(i) for i in range(start*3, end*3)]).to_pandas()\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for ID in range(start, end):\n",
    "        X_signal=[]\n",
    "        y_signal=[]\n",
    "        # for each phase of the signal\n",
    "        for phase in [0,1,2]:\n",
    "            # extract from df_train both signal_id and target to compose the new data sets\n",
    "            signal_id, target = df.loc[ID].loc[phase]\n",
    "            # extract and transform data into sets of features\n",
    "            X_signal.append(transform_ts(praq[str(signal_id)]))\n",
    "            y_signal.append(target)\n",
    "        # concatenate all the 3 phases in one matrix\n",
    "        X_signal=np.concatenate(X_signal,axis=1)\n",
    "        X.append(X_signal)\n",
    "        y.append(y_signal)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    print(X.shape,y.shape)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "52dc826ab9ee1dd56c9fb29bd5c1b2d26b5928bf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this code is very simple, divide the total size of the df_train into two sets and process it\n",
    "\n",
    "def load_all(df,path,n_slit):\n",
    "    X = []\n",
    "    y = []\n",
    "    ID_list = []\n",
    "    start = df.index.levels[0][0]\n",
    "    end = df.index.levels[0][-1]+1\n",
    "    print(start,end)\n",
    "    Nperpart=int((end-start)/n_slit)\n",
    "    \n",
    "    while start+Nperpart < end:\n",
    "        ID_list.append([start,start+Nperpart])\n",
    "        start += Nperpart\n",
    "    ID_list.append([start,end])\n",
    "    \n",
    "    for IDs in tqdm(ID_list):\n",
    "        print(IDs)\n",
    "        X_temp, y_temp = prep_data(df,IDs,path)\n",
    "        X.append(X_temp)\n",
    "        y.append(y_temp)\n",
    "\n",
    "    X = np.concatenate(X,axis=0)\n",
    "    y = np.concatenate(y,axis=0)\n",
    "    return X,y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "f682b2e8a732b2f3145f2cadfaf847b92f726c85"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2904\n",
      "[0, 968]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [15:25<30:50, 925.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(968, 160, 162) (968, 3)\n",
      "[968, 1936]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [30:44<15:23, 923.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(968, 160, 162) (968, 3)\n",
      "[1936, 2904]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [46:18<00:00, 926.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(968, 160, 162) (968, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2904, 160, 162) (2904, 3)\n",
      "CPU times: user 46min 7s, sys: 10.7 s, total: 46min 18s\n",
      "Wall time: 46min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X,y = load_all(df_train,'../input/train.parquet',3)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "289bc7d1ab8048a60025801b457f8df1d848acbc"
   },
   "outputs": [],
   "source": [
    "# This is NN LSTM Model creation\n",
    "def model_lstm(input_shape):\n",
    "    # The shape was explained above, must have this order\n",
    "    inp = Input(shape=(input_shape[1], input_shape[2],))\n",
    "    # This is the LSTM layer\n",
    "    # Bidirecional implies that the 160 chunks are calculated in both ways, 0 to 159 and 159 to zero\n",
    "    # although it appear that just 0 to 159 way matter, I have tested with and without, and tha later worked best\n",
    "    # 128 and 64 are the number of cells used, too many can overfit and too few can underfit\n",
    "    x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(inp)\n",
    "    # The second LSTM can give more fire power to the model, but can overfit it too\n",
    "    x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "    # Attention is a new tecnology that can be applyed to a Recurrent NN to give more meanings to a signal found in the middle\n",
    "    # of the data, it helps more in longs chains of data. A normal RNN give all the responsibility of detect the signal\n",
    "    # to the last cell. Google RNN Attention for more information :)\n",
    "    x = Attention(input_shape[1])(x)\n",
    "    # A intermediate full connected (Dense) can help to deal with nonlinears outputs\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    # x = Dense(64, activation=\"relu\")(x)\n",
    "    # A binnary classification as this must finish with shape (1,)\n",
    "    x = Dense(3, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    # Pay attention in the addition of matthews_correlation metric in the compilation, it is a success factor key\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[matthews_correlation])\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "2ef917ebc557809c2c3590dff6cdcc93678fc899"
   },
   "outputs": [],
   "source": [
    "# Here is where the training happens\n",
    "# First, create a set of indexes of the 5 folds\n",
    "splits = list(StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=2019).split(X, np.zeros(shape=(X.shape[0], 1))))\n",
    "preds_val = []\n",
    "y_val = []\n",
    "cal_list=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "8d6f4ca319c383b1b4f671a37c5a324136e7a466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning fold 1\n",
      "Train on 2323 samples, validate on 581 samples\n",
      "Epoch 1/50\n",
      "2323/2323 [==============================] - 4s 2ms/step - loss: 0.2908 - matthews_correlation: 0.0019 - val_loss: 0.2527 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_0.h5\n",
      "Epoch 2/50\n",
      "2323/2323 [==============================] - 1s 594us/step - loss: 0.2048 - matthews_correlation: 0.0000e+00 - val_loss: 0.2295 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 3/50\n",
      "2323/2323 [==============================] - 1s 599us/step - loss: 0.1777 - matthews_correlation: 0.1486 - val_loss: 0.1781 - val_matthews_correlation: 0.3680\n",
      "\n",
      "Epoch 00003: val_matthews_correlation improved from 0.00000 to 0.36799, saving model to weights_0.h5\n",
      "Epoch 4/50\n",
      "2323/2323 [==============================] - 1s 593us/step - loss: 0.1439 - matthews_correlation: 0.2288 - val_loss: 0.1387 - val_matthews_correlation: 0.4992\n",
      "\n",
      "Epoch 00004: val_matthews_correlation improved from 0.36799 to 0.49921, saving model to weights_0.h5\n",
      "Epoch 5/50\n",
      "2323/2323 [==============================] - 1s 595us/step - loss: 0.1092 - matthews_correlation: 0.5269 - val_loss: 0.1271 - val_matthews_correlation: 0.5150\n",
      "\n",
      "Epoch 00005: val_matthews_correlation improved from 0.49921 to 0.51498, saving model to weights_0.h5\n",
      "Epoch 6/50\n",
      "2323/2323 [==============================] - 1s 608us/step - loss: 0.1212 - matthews_correlation: 0.5241 - val_loss: 0.1192 - val_matthews_correlation: 0.6658\n",
      "\n",
      "Epoch 00006: val_matthews_correlation improved from 0.51498 to 0.66581, saving model to weights_0.h5\n",
      "Epoch 7/50\n",
      "2323/2323 [==============================] - 1s 594us/step - loss: 0.0909 - matthews_correlation: 0.6945 - val_loss: 0.1377 - val_matthews_correlation: 0.6097\n",
      "\n",
      "Epoch 00007: val_matthews_correlation did not improve from 0.66581\n",
      "Epoch 8/50\n",
      "2323/2323 [==============================] - 1s 590us/step - loss: 0.1149 - matthews_correlation: 0.5413 - val_loss: 0.1269 - val_matthews_correlation: 0.5768\n",
      "\n",
      "Epoch 00008: val_matthews_correlation did not improve from 0.66581\n",
      "Epoch 9/50\n",
      "2323/2323 [==============================] - 1s 595us/step - loss: 0.1017 - matthews_correlation: 0.5912 - val_loss: 0.1233 - val_matthews_correlation: 0.6213\n",
      "\n",
      "Epoch 00009: val_matthews_correlation did not improve from 0.66581\n",
      "Epoch 10/50\n",
      "2323/2323 [==============================] - 1s 591us/step - loss: 0.1047 - matthews_correlation: 0.5061 - val_loss: 0.1781 - val_matthews_correlation: 0.5423\n",
      "\n",
      "Epoch 00010: val_matthews_correlation did not improve from 0.66581\n",
      "Epoch 11/50\n",
      "2323/2323 [==============================] - 1s 594us/step - loss: 0.1034 - matthews_correlation: 0.5248 - val_loss: 0.1428 - val_matthews_correlation: 0.6577\n",
      "\n",
      "Epoch 00011: val_matthews_correlation did not improve from 0.66581\n",
      "Epoch 12/50\n",
      "2323/2323 [==============================] - 1s 588us/step - loss: 0.0899 - matthews_correlation: 0.7083 - val_loss: 0.1348 - val_matthews_correlation: 0.5895\n",
      "\n",
      "Epoch 00012: val_matthews_correlation did not improve from 0.66581\n",
      "Epoch 13/50\n",
      "2323/2323 [==============================] - 1s 595us/step - loss: 0.0967 - matthews_correlation: 0.6191 - val_loss: 0.1135 - val_matthews_correlation: 0.6474\n",
      "\n",
      "Epoch 00013: val_matthews_correlation did not improve from 0.66581\n",
      "Epoch 14/50\n",
      "2323/2323 [==============================] - 1s 599us/step - loss: 0.0882 - matthews_correlation: 0.6749 - val_loss: 0.1214 - val_matthews_correlation: 0.6466\n",
      "\n",
      "Epoch 00014: val_matthews_correlation did not improve from 0.66581\n",
      "Epoch 15/50\n",
      "2323/2323 [==============================] - 1s 597us/step - loss: 0.0903 - matthews_correlation: 0.6441 - val_loss: 0.1303 - val_matthews_correlation: 0.6428\n",
      "\n",
      "Epoch 00015: val_matthews_correlation did not improve from 0.66581\n",
      "Epoch 16/50\n",
      "2323/2323 [==============================] - 1s 590us/step - loss: 0.0956 - matthews_correlation: 0.6453 - val_loss: 0.1857 - val_matthews_correlation: 0.5416\n",
      "\n",
      "Epoch 00016: val_matthews_correlation did not improve from 0.66581\n",
      "Epoch 17/50\n",
      "2323/2323 [==============================] - 1s 596us/step - loss: 0.1419 - matthews_correlation: 0.4557 - val_loss: 0.1254 - val_matthews_correlation: 0.6292\n",
      "\n",
      "Epoch 00017: val_matthews_correlation did not improve from 0.66581\n",
      "Epoch 18/50\n",
      "2323/2323 [==============================] - 1s 595us/step - loss: 0.0981 - matthews_correlation: 0.6387 - val_loss: 0.1126 - val_matthews_correlation: 0.6088\n",
      "\n",
      "Epoch 00018: val_matthews_correlation did not improve from 0.66581\n",
      "Epoch 19/50\n",
      "2323/2323 [==============================] - 1s 594us/step - loss: 0.0784 - matthews_correlation: 0.6971 - val_loss: 0.1010 - val_matthews_correlation: 0.6424\n",
      "\n",
      "Epoch 00019: val_matthews_correlation did not improve from 0.66581\n",
      "Epoch 20/50\n",
      "2323/2323 [==============================] - 1s 596us/step - loss: 0.0715 - matthews_correlation: 0.7188 - val_loss: 0.1555 - val_matthews_correlation: 0.5964\n",
      "\n",
      "Epoch 00020: val_matthews_correlation did not improve from 0.66581\n",
      "Epoch 21/50\n",
      "2323/2323 [==============================] - 1s 594us/step - loss: 0.0915 - matthews_correlation: 0.6258 - val_loss: 0.1033 - val_matthews_correlation: 0.6497\n",
      "\n",
      "Epoch 00021: val_matthews_correlation did not improve from 0.66581\n",
      "Epoch 22/50\n",
      "2323/2323 [==============================] - 1s 599us/step - loss: 0.0738 - matthews_correlation: 0.7212 - val_loss: 0.0954 - val_matthews_correlation: 0.6837\n",
      "\n",
      "Epoch 00022: val_matthews_correlation improved from 0.66581 to 0.68373, saving model to weights_0.h5\n",
      "Epoch 23/50\n",
      "2323/2323 [==============================] - 1s 592us/step - loss: 0.0712 - matthews_correlation: 0.7424 - val_loss: 0.1203 - val_matthews_correlation: 0.6786\n",
      "\n",
      "Epoch 00023: val_matthews_correlation did not improve from 0.68373\n",
      "Epoch 24/50\n",
      "2323/2323 [==============================] - 1s 593us/step - loss: 0.0821 - matthews_correlation: 0.7169 - val_loss: 0.1302 - val_matthews_correlation: 0.5967\n",
      "\n",
      "Epoch 00024: val_matthews_correlation did not improve from 0.68373\n",
      "Epoch 25/50\n",
      "2323/2323 [==============================] - 1s 592us/step - loss: 0.0809 - matthews_correlation: 0.7128 - val_loss: 0.1137 - val_matthews_correlation: 0.6879\n",
      "\n",
      "Epoch 00025: val_matthews_correlation improved from 0.68373 to 0.68789, saving model to weights_0.h5\n",
      "Epoch 26/50\n",
      "2323/2323 [==============================] - 1s 595us/step - loss: 0.0770 - matthews_correlation: 0.7016 - val_loss: 0.1148 - val_matthews_correlation: 0.6794\n",
      "\n",
      "Epoch 00026: val_matthews_correlation did not improve from 0.68789\n",
      "Epoch 27/50\n",
      "2323/2323 [==============================] - 1s 596us/step - loss: 0.0885 - matthews_correlation: 0.6769 - val_loss: 0.1314 - val_matthews_correlation: 0.6049\n",
      "\n",
      "Epoch 00027: val_matthews_correlation did not improve from 0.68789\n",
      "Epoch 28/50\n",
      "2323/2323 [==============================] - 1s 591us/step - loss: 0.0824 - matthews_correlation: 0.6801 - val_loss: 0.1054 - val_matthews_correlation: 0.6736\n",
      "\n",
      "Epoch 00028: val_matthews_correlation did not improve from 0.68789\n",
      "Epoch 29/50\n",
      "2323/2323 [==============================] - 1s 594us/step - loss: 0.0745 - matthews_correlation: 0.7176 - val_loss: 0.1271 - val_matthews_correlation: 0.6565\n",
      "\n",
      "Epoch 00029: val_matthews_correlation did not improve from 0.68789\n",
      "Epoch 30/50\n",
      "2323/2323 [==============================] - 1s 593us/step - loss: 0.0774 - matthews_correlation: 0.7052 - val_loss: 0.0980 - val_matthews_correlation: 0.6724\n",
      "\n",
      "Epoch 00030: val_matthews_correlation did not improve from 0.68789\n",
      "Epoch 31/50\n",
      "2323/2323 [==============================] - 1s 588us/step - loss: 0.0653 - matthews_correlation: 0.7656 - val_loss: 0.1047 - val_matthews_correlation: 0.6247\n",
      "\n",
      "Epoch 00031: val_matthews_correlation did not improve from 0.68789\n",
      "Epoch 32/50\n",
      "2323/2323 [==============================] - 1s 597us/step - loss: 0.0623 - matthews_correlation: 0.7654 - val_loss: 0.1480 - val_matthews_correlation: 0.6258\n",
      "\n",
      "Epoch 00032: val_matthews_correlation did not improve from 0.68789\n",
      "Epoch 33/50\n",
      "2323/2323 [==============================] - 1s 589us/step - loss: 0.0990 - matthews_correlation: 0.6132 - val_loss: 0.0977 - val_matthews_correlation: 0.6755\n",
      "\n",
      "Epoch 00033: val_matthews_correlation did not improve from 0.68789\n",
      "Epoch 34/50\n",
      "2323/2323 [==============================] - 1s 596us/step - loss: 0.0734 - matthews_correlation: 0.7364 - val_loss: 0.1055 - val_matthews_correlation: 0.6784\n",
      "\n",
      "Epoch 00034: val_matthews_correlation did not improve from 0.68789\n",
      "Epoch 35/50\n",
      "2323/2323 [==============================] - 1s 592us/step - loss: 0.0710 - matthews_correlation: 0.7294 - val_loss: 0.0999 - val_matthews_correlation: 0.6500\n",
      "\n",
      "Epoch 00035: val_matthews_correlation did not improve from 0.68789\n",
      "Epoch 36/50\n",
      "2323/2323 [==============================] - 1s 591us/step - loss: 0.0649 - matthews_correlation: 0.7777 - val_loss: 0.1140 - val_matthews_correlation: 0.6665\n",
      "\n",
      "Epoch 00036: val_matthews_correlation did not improve from 0.68789\n",
      "Epoch 37/50\n",
      "2323/2323 [==============================] - 1s 590us/step - loss: 0.0607 - matthews_correlation: 0.7814 - val_loss: 0.1096 - val_matthews_correlation: 0.6795\n",
      "\n",
      "Epoch 00037: val_matthews_correlation did not improve from 0.68789\n",
      "Epoch 38/50\n",
      "2323/2323 [==============================] - 1s 589us/step - loss: 0.0626 - matthews_correlation: 0.8005 - val_loss: 0.1111 - val_matthews_correlation: 0.6797\n",
      "\n",
      "Epoch 00038: val_matthews_correlation did not improve from 0.68789\n",
      "Epoch 39/50\n",
      "2323/2323 [==============================] - 1s 596us/step - loss: 0.0564 - matthews_correlation: 0.7953 - val_loss: 0.1158 - val_matthews_correlation: 0.6683\n",
      "\n",
      "Epoch 00039: val_matthews_correlation did not improve from 0.68789\n",
      "Epoch 40/50\n",
      "2323/2323 [==============================] - 1s 595us/step - loss: 0.0585 - matthews_correlation: 0.7871 - val_loss: 0.1138 - val_matthews_correlation: 0.6415\n",
      "\n",
      "Epoch 00040: val_matthews_correlation did not improve from 0.68789\n",
      "Epoch 41/50\n",
      "2323/2323 [==============================] - 1s 594us/step - loss: 0.0564 - matthews_correlation: 0.8145 - val_loss: 0.1157 - val_matthews_correlation: 0.6911\n",
      "\n",
      "Epoch 00041: val_matthews_correlation improved from 0.68789 to 0.69107, saving model to weights_0.h5\n",
      "Epoch 42/50\n",
      "2323/2323 [==============================] - 1s 594us/step - loss: 0.0530 - matthews_correlation: 0.8222 - val_loss: 0.1111 - val_matthews_correlation: 0.6397\n",
      "\n",
      "Epoch 00042: val_matthews_correlation did not improve from 0.69107\n",
      "Epoch 43/50\n",
      "2323/2323 [==============================] - 1s 592us/step - loss: 0.0529 - matthews_correlation: 0.8167 - val_loss: 0.1591 - val_matthews_correlation: 0.6440\n",
      "\n",
      "Epoch 00043: val_matthews_correlation did not improve from 0.69107\n",
      "Epoch 44/50\n",
      "2323/2323 [==============================] - 1s 591us/step - loss: 0.0577 - matthews_correlation: 0.7922 - val_loss: 0.1094 - val_matthews_correlation: 0.6757\n",
      "\n",
      "Epoch 00044: val_matthews_correlation did not improve from 0.69107\n",
      "Epoch 45/50\n",
      "2323/2323 [==============================] - 1s 627us/step - loss: 0.0593 - matthews_correlation: 0.7862 - val_loss: 0.1118 - val_matthews_correlation: 0.6567\n",
      "\n",
      "Epoch 00045: val_matthews_correlation did not improve from 0.69107\n",
      "Epoch 46/50\n",
      "2323/2323 [==============================] - 1s 596us/step - loss: 0.0619 - matthews_correlation: 0.7662 - val_loss: 0.0975 - val_matthews_correlation: 0.6547\n",
      "\n",
      "Epoch 00046: val_matthews_correlation did not improve from 0.69107\n",
      "Epoch 47/50\n",
      "2323/2323 [==============================] - 1s 601us/step - loss: 0.0605 - matthews_correlation: 0.7549 - val_loss: 0.1318 - val_matthews_correlation: 0.6403\n",
      "\n",
      "Epoch 00047: val_matthews_correlation did not improve from 0.69107\n",
      "Epoch 48/50\n",
      "2323/2323 [==============================] - 1s 598us/step - loss: 0.0595 - matthews_correlation: 0.7873 - val_loss: 0.1110 - val_matthews_correlation: 0.6778\n",
      "\n",
      "Epoch 00048: val_matthews_correlation did not improve from 0.69107\n",
      "Epoch 49/50\n",
      "2323/2323 [==============================] - 1s 600us/step - loss: 0.0611 - matthews_correlation: 0.7607 - val_loss: 0.0972 - val_matthews_correlation: 0.6921\n",
      "\n",
      "Epoch 00049: val_matthews_correlation improved from 0.69107 to 0.69211, saving model to weights_0.h5\n",
      "Epoch 50/50\n",
      "2323/2323 [==============================] - 1s 596us/step - loss: 0.0520 - matthews_correlation: 0.8145 - val_loss: 0.1240 - val_matthews_correlation: 0.6968\n",
      "\n",
      "Epoch 00050: val_matthews_correlation improved from 0.69211 to 0.69679, saving model to weights_0.h5\n",
      "Beginning fold 2\n",
      "Train on 2323 samples, validate on 581 samples\n",
      "Epoch 1/50\n",
      "2323/2323 [==============================] - 3s 1ms/step - loss: 0.2989 - matthews_correlation: 0.0043 - val_loss: 0.2042 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_1.h5\n",
      "Epoch 2/50\n",
      "2323/2323 [==============================] - 1s 606us/step - loss: 0.2146 - matthews_correlation: 0.0075 - val_loss: 0.1733 - val_matthews_correlation: 0.1338\n",
      "\n",
      "Epoch 00002: val_matthews_correlation improved from 0.00000 to 0.13378, saving model to weights_1.h5\n",
      "Epoch 3/50\n",
      "2323/2323 [==============================] - 1s 609us/step - loss: 0.1613 - matthews_correlation: 0.2357 - val_loss: 0.1005 - val_matthews_correlation: 0.3387\n",
      "\n",
      "Epoch 00003: val_matthews_correlation improved from 0.13378 to 0.33871, saving model to weights_1.h5\n",
      "Epoch 4/50\n",
      "2323/2323 [==============================] - 1s 607us/step - loss: 0.1285 - matthews_correlation: 0.4905 - val_loss: 0.0970 - val_matthews_correlation: 0.3597\n",
      "\n",
      "Epoch 00004: val_matthews_correlation improved from 0.33871 to 0.35970, saving model to weights_1.h5\n",
      "Epoch 5/50\n",
      "2323/2323 [==============================] - 1s 607us/step - loss: 0.1125 - matthews_correlation: 0.6000 - val_loss: 0.1036 - val_matthews_correlation: 0.4512\n",
      "\n",
      "Epoch 00005: val_matthews_correlation improved from 0.35970 to 0.45123, saving model to weights_1.h5\n",
      "Epoch 6/50\n",
      "2323/2323 [==============================] - 1s 605us/step - loss: 0.1048 - matthews_correlation: 0.6832 - val_loss: 0.1016 - val_matthews_correlation: 0.6718\n",
      "\n",
      "Epoch 00006: val_matthews_correlation improved from 0.45123 to 0.67182, saving model to weights_1.h5\n",
      "Epoch 7/50\n",
      "2323/2323 [==============================] - 1s 606us/step - loss: 0.1305 - matthews_correlation: 0.5769 - val_loss: 0.0804 - val_matthews_correlation: 0.5815\n",
      "\n",
      "Epoch 00007: val_matthews_correlation did not improve from 0.67182\n",
      "Epoch 8/50\n",
      "2323/2323 [==============================] - 1s 610us/step - loss: 0.1019 - matthews_correlation: 0.6525 - val_loss: 0.0778 - val_matthews_correlation: 0.5514\n",
      "\n",
      "Epoch 00008: val_matthews_correlation did not improve from 0.67182\n",
      "Epoch 9/50\n",
      "2323/2323 [==============================] - 1s 607us/step - loss: 0.0944 - matthews_correlation: 0.6943 - val_loss: 0.0947 - val_matthews_correlation: 0.5181\n",
      "\n",
      "Epoch 00009: val_matthews_correlation did not improve from 0.67182\n",
      "Epoch 10/50\n",
      "2323/2323 [==============================] - 1s 606us/step - loss: 0.0936 - matthews_correlation: 0.6944 - val_loss: 0.1176 - val_matthews_correlation: 0.4140\n",
      "\n",
      "Epoch 00010: val_matthews_correlation did not improve from 0.67182\n",
      "Epoch 11/50\n",
      "2323/2323 [==============================] - 1s 611us/step - loss: 0.1085 - matthews_correlation: 0.6875 - val_loss: 0.0975 - val_matthews_correlation: 0.4506\n",
      "\n",
      "Epoch 00011: val_matthews_correlation did not improve from 0.67182\n",
      "Epoch 12/50\n",
      "2323/2323 [==============================] - 1s 609us/step - loss: 0.1015 - matthews_correlation: 0.6842 - val_loss: 0.0807 - val_matthews_correlation: 0.4930\n",
      "\n",
      "Epoch 00012: val_matthews_correlation did not improve from 0.67182\n",
      "Epoch 13/50\n",
      "2323/2323 [==============================] - 1s 608us/step - loss: 0.0866 - matthews_correlation: 0.7011 - val_loss: 0.0706 - val_matthews_correlation: 0.5285\n",
      "\n",
      "Epoch 00013: val_matthews_correlation did not improve from 0.67182\n",
      "Epoch 14/50\n",
      "2323/2323 [==============================] - 1s 607us/step - loss: 0.0873 - matthews_correlation: 0.7101 - val_loss: 0.0744 - val_matthews_correlation: 0.5380\n",
      "\n",
      "Epoch 00014: val_matthews_correlation did not improve from 0.67182\n",
      "Epoch 15/50\n",
      "2323/2323 [==============================] - 1s 611us/step - loss: 0.0823 - matthews_correlation: 0.7090 - val_loss: 0.0797 - val_matthews_correlation: 0.7211\n",
      "\n",
      "Epoch 00015: val_matthews_correlation improved from 0.67182 to 0.72111, saving model to weights_1.h5\n",
      "Epoch 16/50\n",
      "2323/2323 [==============================] - 1s 610us/step - loss: 0.0976 - matthews_correlation: 0.6884 - val_loss: 0.0787 - val_matthews_correlation: 0.5107\n",
      "\n",
      "Epoch 00016: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 17/50\n",
      "2323/2323 [==============================] - 1s 610us/step - loss: 0.0874 - matthews_correlation: 0.6953 - val_loss: 0.0822 - val_matthews_correlation: 0.5374\n",
      "\n",
      "Epoch 00017: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 18/50\n",
      "2323/2323 [==============================] - 1s 611us/step - loss: 0.0888 - matthews_correlation: 0.7391 - val_loss: 0.0830 - val_matthews_correlation: 0.4985\n",
      "\n",
      "Epoch 00018: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 19/50\n",
      "2323/2323 [==============================] - 1s 611us/step - loss: 0.0887 - matthews_correlation: 0.7223 - val_loss: 0.1065 - val_matthews_correlation: 0.4461\n",
      "\n",
      "Epoch 00019: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 20/50\n",
      "2323/2323 [==============================] - 1s 609us/step - loss: 0.0822 - matthews_correlation: 0.7502 - val_loss: 0.0924 - val_matthews_correlation: 0.4889\n",
      "\n",
      "Epoch 00020: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 21/50\n",
      "2323/2323 [==============================] - 1s 606us/step - loss: 0.0869 - matthews_correlation: 0.7608 - val_loss: 0.1077 - val_matthews_correlation: 0.3897\n",
      "\n",
      "Epoch 00021: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 22/50\n",
      "2323/2323 [==============================] - 1s 606us/step - loss: 0.0859 - matthews_correlation: 0.7117 - val_loss: 0.0765 - val_matthews_correlation: 0.5683\n",
      "\n",
      "Epoch 00022: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 23/50\n",
      "2323/2323 [==============================] - 1s 609us/step - loss: 0.0853 - matthews_correlation: 0.7132 - val_loss: 0.0747 - val_matthews_correlation: 0.5518\n",
      "\n",
      "Epoch 00023: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 24/50\n",
      "2323/2323 [==============================] - 1s 607us/step - loss: 0.0771 - matthews_correlation: 0.7428 - val_loss: 0.0805 - val_matthews_correlation: 0.5124\n",
      "\n",
      "Epoch 00024: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 25/50\n",
      "2323/2323 [==============================] - 1s 610us/step - loss: 0.0777 - matthews_correlation: 0.7610 - val_loss: 0.0921 - val_matthews_correlation: 0.4787\n",
      "\n",
      "Epoch 00025: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 26/50\n",
      "2323/2323 [==============================] - 1s 602us/step - loss: 0.0940 - matthews_correlation: 0.7163 - val_loss: 0.1114 - val_matthews_correlation: 0.3835\n",
      "\n",
      "Epoch 00026: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 27/50\n",
      "2323/2323 [==============================] - 1s 605us/step - loss: 0.1003 - matthews_correlation: 0.6815 - val_loss: 0.0752 - val_matthews_correlation: 0.5201\n",
      "\n",
      "Epoch 00027: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 28/50\n",
      "2323/2323 [==============================] - 1s 603us/step - loss: 0.0806 - matthews_correlation: 0.7340 - val_loss: 0.0699 - val_matthews_correlation: 0.5668\n",
      "\n",
      "Epoch 00028: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 29/50\n",
      "2323/2323 [==============================] - 1s 605us/step - loss: 0.0769 - matthews_correlation: 0.7544 - val_loss: 0.1131 - val_matthews_correlation: 0.4649\n",
      "\n",
      "Epoch 00029: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 30/50\n",
      "2323/2323 [==============================] - 1s 572us/step - loss: 0.0917 - matthews_correlation: 0.7069 - val_loss: 0.0819 - val_matthews_correlation: 0.5165\n",
      "\n",
      "Epoch 00030: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 31/50\n",
      "2323/2323 [==============================] - 1s 573us/step - loss: 0.0795 - matthews_correlation: 0.7296 - val_loss: 0.0700 - val_matthews_correlation: 0.5722\n",
      "\n",
      "Epoch 00031: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 32/50\n",
      "2323/2323 [==============================] - 1s 579us/step - loss: 0.0818 - matthews_correlation: 0.7453 - val_loss: 0.0973 - val_matthews_correlation: 0.4506\n",
      "\n",
      "Epoch 00032: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 33/50\n",
      "2323/2323 [==============================] - 1s 587us/step - loss: 0.0747 - matthews_correlation: 0.7573 - val_loss: 0.0687 - val_matthews_correlation: 0.5668\n",
      "\n",
      "Epoch 00033: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 34/50\n",
      "2323/2323 [==============================] - 1s 607us/step - loss: 0.0791 - matthews_correlation: 0.7631 - val_loss: 0.0860 - val_matthews_correlation: 0.5369\n",
      "\n",
      "Epoch 00034: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 35/50\n",
      "2323/2323 [==============================] - 1s 608us/step - loss: 0.0751 - matthews_correlation: 0.7694 - val_loss: 0.0863 - val_matthews_correlation: 0.5449\n",
      "\n",
      "Epoch 00035: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 36/50\n",
      "2323/2323 [==============================] - 1s 608us/step - loss: 0.0735 - matthews_correlation: 0.7389 - val_loss: 0.0876 - val_matthews_correlation: 0.5474\n",
      "\n",
      "Epoch 00036: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 37/50\n",
      "2323/2323 [==============================] - 1s 609us/step - loss: 0.0773 - matthews_correlation: 0.7339 - val_loss: 0.0793 - val_matthews_correlation: 0.5818\n",
      "\n",
      "Epoch 00037: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 38/50\n",
      "2323/2323 [==============================] - 1s 622us/step - loss: 0.0722 - matthews_correlation: 0.7655 - val_loss: 0.0824 - val_matthews_correlation: 0.5904\n",
      "\n",
      "Epoch 00038: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 39/50\n",
      "2323/2323 [==============================] - 1s 608us/step - loss: 0.0879 - matthews_correlation: 0.7056 - val_loss: 0.0870 - val_matthews_correlation: 0.4535\n",
      "\n",
      "Epoch 00039: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 40/50\n",
      "2323/2323 [==============================] - 1s 610us/step - loss: 0.0751 - matthews_correlation: 0.7581 - val_loss: 0.0722 - val_matthews_correlation: 0.6279\n",
      "\n",
      "Epoch 00040: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 41/50\n",
      "2323/2323 [==============================] - 1s 608us/step - loss: 0.0736 - matthews_correlation: 0.7672 - val_loss: 0.0693 - val_matthews_correlation: 0.5656\n",
      "\n",
      "Epoch 00041: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 42/50\n",
      "2323/2323 [==============================] - 1s 609us/step - loss: 0.0643 - matthews_correlation: 0.8040 - val_loss: 0.0797 - val_matthews_correlation: 0.5311\n",
      "\n",
      "Epoch 00042: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 43/50\n",
      "2323/2323 [==============================] - 1s 610us/step - loss: 0.0622 - matthews_correlation: 0.8234 - val_loss: 0.0814 - val_matthews_correlation: 0.5487\n",
      "\n",
      "Epoch 00043: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 44/50\n",
      "2323/2323 [==============================] - 1s 609us/step - loss: 0.0796 - matthews_correlation: 0.7525 - val_loss: 0.0712 - val_matthews_correlation: 0.5581\n",
      "\n",
      "Epoch 00044: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 45/50\n",
      "2323/2323 [==============================] - 1s 609us/step - loss: 0.0730 - matthews_correlation: 0.7789 - val_loss: 0.0760 - val_matthews_correlation: 0.6015\n",
      "\n",
      "Epoch 00045: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 46/50\n",
      "2323/2323 [==============================] - 1s 605us/step - loss: 0.0675 - matthews_correlation: 0.7765 - val_loss: 0.0874 - val_matthews_correlation: 0.5344\n",
      "\n",
      "Epoch 00046: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 47/50\n",
      "2323/2323 [==============================] - 1s 608us/step - loss: 0.0716 - matthews_correlation: 0.7783 - val_loss: 0.0732 - val_matthews_correlation: 0.6281\n",
      "\n",
      "Epoch 00047: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 48/50\n",
      "2323/2323 [==============================] - 1s 612us/step - loss: 0.0734 - matthews_correlation: 0.7733 - val_loss: 0.0998 - val_matthews_correlation: 0.5025\n",
      "\n",
      "Epoch 00048: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 49/50\n",
      "2323/2323 [==============================] - 1s 610us/step - loss: 0.0852 - matthews_correlation: 0.6783 - val_loss: 0.0768 - val_matthews_correlation: 0.5214\n",
      "\n",
      "Epoch 00049: val_matthews_correlation did not improve from 0.72111\n",
      "Epoch 50/50\n",
      "2323/2323 [==============================] - 1s 608us/step - loss: 0.0758 - matthews_correlation: 0.7400 - val_loss: 0.1053 - val_matthews_correlation: 0.4506\n",
      "\n",
      "Epoch 00050: val_matthews_correlation did not improve from 0.72111\n",
      "Beginning fold 3\n",
      "Train on 2323 samples, validate on 581 samples\n",
      "Epoch 1/50\n",
      "2323/2323 [==============================] - 3s 1ms/step - loss: 0.2820 - matthews_correlation: 0.0038 - val_loss: 0.2280 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_2.h5\n",
      "Epoch 2/50\n",
      "2323/2323 [==============================] - 1s 613us/step - loss: 0.1778 - matthews_correlation: 0.0338 - val_loss: 0.1692 - val_matthews_correlation: 0.1520\n",
      "\n",
      "Epoch 00002: val_matthews_correlation improved from 0.00000 to 0.15198, saving model to weights_2.h5\n",
      "Epoch 3/50\n",
      "2323/2323 [==============================] - 1s 607us/step - loss: 0.1563 - matthews_correlation: 0.2728 - val_loss: 0.1561 - val_matthews_correlation: 0.4523\n",
      "\n",
      "Epoch 00003: val_matthews_correlation improved from 0.15198 to 0.45229, saving model to weights_2.h5\n",
      "Epoch 4/50\n",
      "2323/2323 [==============================] - 1s 607us/step - loss: 0.1213 - matthews_correlation: 0.4811 - val_loss: 0.1414 - val_matthews_correlation: 0.6185\n",
      "\n",
      "Epoch 00004: val_matthews_correlation improved from 0.45229 to 0.61850, saving model to weights_2.h5\n",
      "Epoch 5/50\n",
      "2323/2323 [==============================] - 1s 609us/step - loss: 0.1065 - matthews_correlation: 0.6105 - val_loss: 0.1601 - val_matthews_correlation: 0.5442\n",
      "\n",
      "Epoch 00005: val_matthews_correlation did not improve from 0.61850\n",
      "Epoch 6/50\n",
      "2323/2323 [==============================] - 1s 610us/step - loss: 0.1059 - matthews_correlation: 0.6205 - val_loss: 0.1477 - val_matthews_correlation: 0.4955\n",
      "\n",
      "Epoch 00006: val_matthews_correlation did not improve from 0.61850\n",
      "Epoch 7/50\n",
      "2323/2323 [==============================] - 1s 610us/step - loss: 0.0974 - matthews_correlation: 0.6465 - val_loss: 0.1398 - val_matthews_correlation: 0.6195\n",
      "\n",
      "Epoch 00007: val_matthews_correlation improved from 0.61850 to 0.61951, saving model to weights_2.h5\n",
      "Epoch 8/50\n",
      "2323/2323 [==============================] - 1s 606us/step - loss: 0.0893 - matthews_correlation: 0.6575 - val_loss: 0.1732 - val_matthews_correlation: 0.5507\n",
      "\n",
      "Epoch 00008: val_matthews_correlation did not improve from 0.61951\n",
      "Epoch 9/50\n",
      "2323/2323 [==============================] - 1s 607us/step - loss: 0.1036 - matthews_correlation: 0.6532 - val_loss: 0.1392 - val_matthews_correlation: 0.6369\n",
      "\n",
      "Epoch 00009: val_matthews_correlation improved from 0.61951 to 0.63688, saving model to weights_2.h5\n",
      "Epoch 10/50\n",
      "2323/2323 [==============================] - 1s 608us/step - loss: 0.1007 - matthews_correlation: 0.6220 - val_loss: 0.1336 - val_matthews_correlation: 0.5740\n",
      "\n",
      "Epoch 00010: val_matthews_correlation did not improve from 0.63688\n",
      "Epoch 11/50\n",
      "2323/2323 [==============================] - 1s 606us/step - loss: 0.0933 - matthews_correlation: 0.6402 - val_loss: 0.1368 - val_matthews_correlation: 0.6493\n",
      "\n",
      "Epoch 00011: val_matthews_correlation improved from 0.63688 to 0.64933, saving model to weights_2.h5\n",
      "Epoch 12/50\n",
      "2323/2323 [==============================] - 1s 610us/step - loss: 0.0978 - matthews_correlation: 0.6139 - val_loss: 0.1354 - val_matthews_correlation: 0.6305\n",
      "\n",
      "Epoch 00012: val_matthews_correlation did not improve from 0.64933\n",
      "Epoch 13/50\n",
      "2323/2323 [==============================] - 1s 610us/step - loss: 0.0850 - matthews_correlation: 0.6709 - val_loss: 0.1612 - val_matthews_correlation: 0.6084\n",
      "\n",
      "Epoch 00013: val_matthews_correlation did not improve from 0.64933\n",
      "Epoch 14/50\n",
      "2323/2323 [==============================] - 1s 606us/step - loss: 0.0843 - matthews_correlation: 0.7232 - val_loss: 0.1391 - val_matthews_correlation: 0.6661\n",
      "\n",
      "Epoch 00014: val_matthews_correlation improved from 0.64933 to 0.66610, saving model to weights_2.h5\n",
      "Epoch 15/50\n",
      "2323/2323 [==============================] - 1s 604us/step - loss: 0.0751 - matthews_correlation: 0.7554 - val_loss: 0.1230 - val_matthews_correlation: 0.5846\n",
      "\n",
      "Epoch 00015: val_matthews_correlation did not improve from 0.66610\n",
      "Epoch 16/50\n",
      "2323/2323 [==============================] - 1s 607us/step - loss: 0.0748 - matthews_correlation: 0.7375 - val_loss: 0.1305 - val_matthews_correlation: 0.6627\n",
      "\n",
      "Epoch 00016: val_matthews_correlation did not improve from 0.66610\n",
      "Epoch 17/50\n",
      "2323/2323 [==============================] - 1s 608us/step - loss: 0.0812 - matthews_correlation: 0.7147 - val_loss: 0.1676 - val_matthews_correlation: 0.5930\n",
      "\n",
      "Epoch 00017: val_matthews_correlation did not improve from 0.66610\n",
      "Epoch 18/50\n",
      "2323/2323 [==============================] - 1s 609us/step - loss: 0.0823 - matthews_correlation: 0.6661 - val_loss: 0.1392 - val_matthews_correlation: 0.6373\n",
      "\n",
      "Epoch 00018: val_matthews_correlation did not improve from 0.66610\n",
      "Epoch 19/50\n",
      "2323/2323 [==============================] - 1s 617us/step - loss: 0.0789 - matthews_correlation: 0.7372 - val_loss: 0.1272 - val_matthews_correlation: 0.6516\n",
      "\n",
      "Epoch 00019: val_matthews_correlation did not improve from 0.66610\n",
      "Epoch 20/50\n",
      "2323/2323 [==============================] - 1s 611us/step - loss: 0.0701 - matthews_correlation: 0.7226 - val_loss: 0.1298 - val_matthews_correlation: 0.6914\n",
      "\n",
      "Epoch 00020: val_matthews_correlation improved from 0.66610 to 0.69140, saving model to weights_2.h5\n",
      "Epoch 21/50\n",
      "2323/2323 [==============================] - 1s 609us/step - loss: 0.0661 - matthews_correlation: 0.7459 - val_loss: 0.1722 - val_matthews_correlation: 0.6536\n",
      "\n",
      "Epoch 00021: val_matthews_correlation did not improve from 0.69140\n",
      "Epoch 22/50\n",
      "2323/2323 [==============================] - 1s 609us/step - loss: 0.0863 - matthews_correlation: 0.6926 - val_loss: 0.1339 - val_matthews_correlation: 0.6384\n",
      "\n",
      "Epoch 00022: val_matthews_correlation did not improve from 0.69140\n",
      "Epoch 23/50\n",
      "2323/2323 [==============================] - 1s 609us/step - loss: 0.0737 - matthews_correlation: 0.7545 - val_loss: 0.1292 - val_matthews_correlation: 0.6337\n",
      "\n",
      "Epoch 00023: val_matthews_correlation did not improve from 0.69140\n",
      "Epoch 24/50\n",
      "2323/2323 [==============================] - 1s 612us/step - loss: 0.0666 - matthews_correlation: 0.7583 - val_loss: 0.1522 - val_matthews_correlation: 0.6441\n",
      "\n",
      "Epoch 00024: val_matthews_correlation did not improve from 0.69140\n",
      "Epoch 25/50\n",
      "2323/2323 [==============================] - 1s 605us/step - loss: 0.0712 - matthews_correlation: 0.7399 - val_loss: 0.1240 - val_matthews_correlation: 0.6999\n",
      "\n",
      "Epoch 00025: val_matthews_correlation improved from 0.69140 to 0.69994, saving model to weights_2.h5\n",
      "Epoch 26/50\n",
      "2323/2323 [==============================] - 1s 608us/step - loss: 0.0746 - matthews_correlation: 0.7464 - val_loss: 0.1368 - val_matthews_correlation: 0.6043\n",
      "\n",
      "Epoch 00026: val_matthews_correlation did not improve from 0.69994\n",
      "Epoch 27/50\n",
      "2323/2323 [==============================] - 1s 616us/step - loss: 0.0655 - matthews_correlation: 0.7599 - val_loss: 0.1235 - val_matthews_correlation: 0.6556\n",
      "\n",
      "Epoch 00027: val_matthews_correlation did not improve from 0.69994\n",
      "Epoch 28/50\n",
      "2323/2323 [==============================] - 1s 605us/step - loss: 0.0623 - matthews_correlation: 0.7652 - val_loss: 0.1388 - val_matthews_correlation: 0.6435\n",
      "\n",
      "Epoch 00028: val_matthews_correlation did not improve from 0.69994\n",
      "Epoch 29/50\n",
      "2323/2323 [==============================] - 1s 609us/step - loss: 0.0682 - matthews_correlation: 0.7294 - val_loss: 0.1342 - val_matthews_correlation: 0.6749\n",
      "\n",
      "Epoch 00029: val_matthews_correlation did not improve from 0.69994\n",
      "Epoch 30/50\n",
      "2323/2323 [==============================] - 1s 606us/step - loss: 0.0723 - matthews_correlation: 0.7061 - val_loss: 0.2690 - val_matthews_correlation: 0.5196\n",
      "\n",
      "Epoch 00030: val_matthews_correlation did not improve from 0.69994\n",
      "Epoch 31/50\n",
      "2323/2323 [==============================] - 1s 608us/step - loss: 0.0984 - matthews_correlation: 0.6739 - val_loss: 0.1447 - val_matthews_correlation: 0.6294\n",
      "\n",
      "Epoch 00031: val_matthews_correlation did not improve from 0.69994\n",
      "Epoch 32/50\n",
      "2323/2323 [==============================] - 1s 611us/step - loss: 0.0907 - matthews_correlation: 0.7098 - val_loss: 0.1213 - val_matthews_correlation: 0.7206\n",
      "\n",
      "Epoch 00032: val_matthews_correlation improved from 0.69994 to 0.72061, saving model to weights_2.h5\n",
      "Epoch 33/50\n",
      "2323/2323 [==============================] - 1s 605us/step - loss: 0.0712 - matthews_correlation: 0.7679 - val_loss: 0.1159 - val_matthews_correlation: 0.6957\n",
      "\n",
      "Epoch 00033: val_matthews_correlation did not improve from 0.72061\n",
      "Epoch 34/50\n",
      "2323/2323 [==============================] - 1s 604us/step - loss: 0.0665 - matthews_correlation: 0.7809 - val_loss: 0.1332 - val_matthews_correlation: 0.6581\n",
      "\n",
      "Epoch 00034: val_matthews_correlation did not improve from 0.72061\n",
      "Epoch 35/50\n",
      "2323/2323 [==============================] - 1s 607us/step - loss: 0.0615 - matthews_correlation: 0.7738 - val_loss: 0.1702 - val_matthews_correlation: 0.6367\n",
      "\n",
      "Epoch 00035: val_matthews_correlation did not improve from 0.72061\n",
      "Epoch 36/50\n",
      "2323/2323 [==============================] - 1s 607us/step - loss: 0.0858 - matthews_correlation: 0.7386 - val_loss: 0.1238 - val_matthews_correlation: 0.6845\n",
      "\n",
      "Epoch 00036: val_matthews_correlation did not improve from 0.72061\n",
      "Epoch 37/50\n",
      "2323/2323 [==============================] - 1s 607us/step - loss: 0.0739 - matthews_correlation: 0.7497 - val_loss: 0.1424 - val_matthews_correlation: 0.6629\n",
      "\n",
      "Epoch 00037: val_matthews_correlation did not improve from 0.72061\n",
      "Epoch 38/50\n",
      "2323/2323 [==============================] - 1s 604us/step - loss: 0.0857 - matthews_correlation: 0.7225 - val_loss: 0.1367 - val_matthews_correlation: 0.6616\n",
      "\n",
      "Epoch 00038: val_matthews_correlation did not improve from 0.72061\n",
      "Epoch 39/50\n",
      "2323/2323 [==============================] - 1s 606us/step - loss: 0.0683 - matthews_correlation: 0.7699 - val_loss: 0.1379 - val_matthews_correlation: 0.6614\n",
      "\n",
      "Epoch 00039: val_matthews_correlation did not improve from 0.72061\n",
      "Epoch 40/50\n",
      "2323/2323 [==============================] - 1s 608us/step - loss: 0.0691 - matthews_correlation: 0.7230 - val_loss: 0.1261 - val_matthews_correlation: 0.6614\n",
      "\n",
      "Epoch 00040: val_matthews_correlation did not improve from 0.72061\n",
      "Epoch 41/50\n",
      "2323/2323 [==============================] - 1s 607us/step - loss: 0.0597 - matthews_correlation: 0.7833 - val_loss: 0.1279 - val_matthews_correlation: 0.7079\n",
      "\n",
      "Epoch 00041: val_matthews_correlation did not improve from 0.72061\n",
      "Epoch 42/50\n",
      "2323/2323 [==============================] - 1s 610us/step - loss: 0.0673 - matthews_correlation: 0.7693 - val_loss: 0.1445 - val_matthews_correlation: 0.6826\n",
      "\n",
      "Epoch 00042: val_matthews_correlation did not improve from 0.72061\n",
      "Epoch 43/50\n",
      "2323/2323 [==============================] - 1s 607us/step - loss: 0.0637 - matthews_correlation: 0.7674 - val_loss: 0.1278 - val_matthews_correlation: 0.6852\n",
      "\n",
      "Epoch 00043: val_matthews_correlation did not improve from 0.72061\n",
      "Epoch 44/50\n",
      "2323/2323 [==============================] - 1s 605us/step - loss: 0.0597 - matthews_correlation: 0.7950 - val_loss: 0.1432 - val_matthews_correlation: 0.6660\n",
      "\n",
      "Epoch 00044: val_matthews_correlation did not improve from 0.72061\n",
      "Epoch 45/50\n",
      "2323/2323 [==============================] - 1s 609us/step - loss: 0.0531 - matthews_correlation: 0.7986 - val_loss: 0.1447 - val_matthews_correlation: 0.6942\n",
      "\n",
      "Epoch 00045: val_matthews_correlation did not improve from 0.72061\n",
      "Epoch 46/50\n",
      "2323/2323 [==============================] - 1s 612us/step - loss: 0.0592 - matthews_correlation: 0.7565 - val_loss: 0.1722 - val_matthews_correlation: 0.6534\n",
      "\n",
      "Epoch 00046: val_matthews_correlation did not improve from 0.72061\n",
      "Epoch 47/50\n",
      "2323/2323 [==============================] - 1s 608us/step - loss: 0.0574 - matthews_correlation: 0.7637 - val_loss: 0.1518 - val_matthews_correlation: 0.6440\n",
      "\n",
      "Epoch 00047: val_matthews_correlation did not improve from 0.72061\n",
      "Epoch 48/50\n",
      "2323/2323 [==============================] - 1s 612us/step - loss: 0.0539 - matthews_correlation: 0.7941 - val_loss: 0.1543 - val_matthews_correlation: 0.6612\n",
      "\n",
      "Epoch 00048: val_matthews_correlation did not improve from 0.72061\n",
      "Epoch 49/50\n",
      "2323/2323 [==============================] - 1s 606us/step - loss: 0.0481 - matthews_correlation: 0.8438 - val_loss: 0.1662 - val_matthews_correlation: 0.6139\n",
      "\n",
      "Epoch 00049: val_matthews_correlation did not improve from 0.72061\n",
      "Epoch 50/50\n",
      "2323/2323 [==============================] - 1s 612us/step - loss: 0.0496 - matthews_correlation: 0.8231 - val_loss: 0.1833 - val_matthews_correlation: 0.6419\n",
      "\n",
      "Epoch 00050: val_matthews_correlation did not improve from 0.72061\n",
      "Beginning fold 4\n",
      "Train on 2323 samples, validate on 581 samples\n",
      "Epoch 1/50\n",
      "2323/2323 [==============================] - 3s 1ms/step - loss: 0.3464 - matthews_correlation: -0.0019 - val_loss: 0.2256 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_3.h5\n",
      "Epoch 2/50\n",
      "2323/2323 [==============================] - 1s 597us/step - loss: 0.2259 - matthews_correlation: 0.0000e+00 - val_loss: 0.2041 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 3/50\n",
      "2323/2323 [==============================] - 1s 599us/step - loss: 0.1962 - matthews_correlation: 0.0093 - val_loss: 0.1472 - val_matthews_correlation: 0.1921\n",
      "\n",
      "Epoch 00003: val_matthews_correlation improved from 0.00000 to 0.19208, saving model to weights_3.h5\n",
      "Epoch 4/50\n",
      "2323/2323 [==============================] - 1s 598us/step - loss: 0.1573 - matthews_correlation: 0.2955 - val_loss: 0.1130 - val_matthews_correlation: 0.5081\n",
      "\n",
      "Epoch 00004: val_matthews_correlation improved from 0.19208 to 0.50811, saving model to weights_3.h5\n",
      "Epoch 5/50\n",
      "2323/2323 [==============================] - 1s 601us/step - loss: 0.1239 - matthews_correlation: 0.5294 - val_loss: 0.0895 - val_matthews_correlation: 0.6252\n",
      "\n",
      "Epoch 00005: val_matthews_correlation improved from 0.50811 to 0.62516, saving model to weights_3.h5\n",
      "Epoch 6/50\n",
      "2323/2323 [==============================] - 1s 601us/step - loss: 0.1160 - matthews_correlation: 0.6093 - val_loss: 0.1047 - val_matthews_correlation: 0.7804\n",
      "\n",
      "Epoch 00006: val_matthews_correlation improved from 0.62516 to 0.78044, saving model to weights_3.h5\n",
      "Epoch 7/50\n",
      "2323/2323 [==============================] - 1s 598us/step - loss: 0.1173 - matthews_correlation: 0.5891 - val_loss: 0.0973 - val_matthews_correlation: 0.7450\n",
      "\n",
      "Epoch 00007: val_matthews_correlation did not improve from 0.78044\n",
      "Epoch 8/50\n",
      "2323/2323 [==============================] - 1s 599us/step - loss: 0.1064 - matthews_correlation: 0.6621 - val_loss: 0.0824 - val_matthews_correlation: 0.7066\n",
      "\n",
      "Epoch 00008: val_matthews_correlation did not improve from 0.78044\n",
      "Epoch 9/50\n",
      "2323/2323 [==============================] - 1s 602us/step - loss: 0.0927 - matthews_correlation: 0.7016 - val_loss: 0.0842 - val_matthews_correlation: 0.6322\n",
      "\n",
      "Epoch 00009: val_matthews_correlation did not improve from 0.78044\n",
      "Epoch 10/50\n",
      "2323/2323 [==============================] - 1s 599us/step - loss: 0.0956 - matthews_correlation: 0.6444 - val_loss: 0.0833 - val_matthews_correlation: 0.6224\n",
      "\n",
      "Epoch 00010: val_matthews_correlation did not improve from 0.78044\n",
      "Epoch 11/50\n",
      "2323/2323 [==============================] - 1s 608us/step - loss: 0.0932 - matthews_correlation: 0.6380 - val_loss: 0.0764 - val_matthews_correlation: 0.6786\n",
      "\n",
      "Epoch 00011: val_matthews_correlation did not improve from 0.78044\n",
      "Epoch 12/50\n",
      "2323/2323 [==============================] - 1s 603us/step - loss: 0.0967 - matthews_correlation: 0.6626 - val_loss: 0.0845 - val_matthews_correlation: 0.6259\n",
      "\n",
      "Epoch 00012: val_matthews_correlation did not improve from 0.78044\n",
      "Epoch 13/50\n",
      "2323/2323 [==============================] - 1s 601us/step - loss: 0.0854 - matthews_correlation: 0.6990 - val_loss: 0.0734 - val_matthews_correlation: 0.7733\n",
      "\n",
      "Epoch 00013: val_matthews_correlation did not improve from 0.78044\n",
      "Epoch 14/50\n",
      "2323/2323 [==============================] - 1s 601us/step - loss: 0.0840 - matthews_correlation: 0.6784 - val_loss: 0.1048 - val_matthews_correlation: 0.7061\n",
      "\n",
      "Epoch 00014: val_matthews_correlation did not improve from 0.78044\n",
      "Epoch 15/50\n",
      "2323/2323 [==============================] - 1s 598us/step - loss: 0.0910 - matthews_correlation: 0.6806 - val_loss: 0.1006 - val_matthews_correlation: 0.7051\n",
      "\n",
      "Epoch 00015: val_matthews_correlation did not improve from 0.78044\n",
      "Epoch 16/50\n",
      "2323/2323 [==============================] - 1s 608us/step - loss: 0.1021 - matthews_correlation: 0.6447 - val_loss: 0.0921 - val_matthews_correlation: 0.5699\n",
      "\n",
      "Epoch 00016: val_matthews_correlation did not improve from 0.78044\n",
      "Epoch 17/50\n",
      "2323/2323 [==============================] - 1s 601us/step - loss: 0.0974 - matthews_correlation: 0.6783 - val_loss: 0.0777 - val_matthews_correlation: 0.8247\n",
      "\n",
      "Epoch 00017: val_matthews_correlation improved from 0.78044 to 0.82466, saving model to weights_3.h5\n",
      "Epoch 18/50\n",
      "2323/2323 [==============================] - 1s 598us/step - loss: 0.0878 - matthews_correlation: 0.7189 - val_loss: 0.0844 - val_matthews_correlation: 0.7273\n",
      "\n",
      "Epoch 00018: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 19/50\n",
      "2323/2323 [==============================] - 1s 592us/step - loss: 0.0918 - matthews_correlation: 0.6865 - val_loss: 0.0728 - val_matthews_correlation: 0.7571\n",
      "\n",
      "Epoch 00019: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 20/50\n",
      "2323/2323 [==============================] - 1s 589us/step - loss: 0.0791 - matthews_correlation: 0.7344 - val_loss: 0.0744 - val_matthews_correlation: 0.7185\n",
      "\n",
      "Epoch 00020: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 21/50\n",
      "2323/2323 [==============================] - 1s 592us/step - loss: 0.0766 - matthews_correlation: 0.7468 - val_loss: 0.1035 - val_matthews_correlation: 0.5555\n",
      "\n",
      "Epoch 00021: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 22/50\n",
      "2323/2323 [==============================] - 1s 591us/step - loss: 0.0915 - matthews_correlation: 0.6909 - val_loss: 0.0866 - val_matthews_correlation: 0.7623\n",
      "\n",
      "Epoch 00022: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 23/50\n",
      "2323/2323 [==============================] - 1s 595us/step - loss: 0.0767 - matthews_correlation: 0.7281 - val_loss: 0.0725 - val_matthews_correlation: 0.8209\n",
      "\n",
      "Epoch 00023: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 24/50\n",
      "2323/2323 [==============================] - 1s 592us/step - loss: 0.0724 - matthews_correlation: 0.7560 - val_loss: 0.1028 - val_matthews_correlation: 0.5681\n",
      "\n",
      "Epoch 00024: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 25/50\n",
      "2323/2323 [==============================] - 1s 600us/step - loss: 0.0842 - matthews_correlation: 0.7469 - val_loss: 0.0668 - val_matthews_correlation: 0.8185\n",
      "\n",
      "Epoch 00025: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 26/50\n",
      "2323/2323 [==============================] - 1s 594us/step - loss: 0.0730 - matthews_correlation: 0.7433 - val_loss: 0.0862 - val_matthews_correlation: 0.6625\n",
      "\n",
      "Epoch 00026: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 27/50\n",
      "2323/2323 [==============================] - 1s 595us/step - loss: 0.0791 - matthews_correlation: 0.7218 - val_loss: 0.0852 - val_matthews_correlation: 0.6687\n",
      "\n",
      "Epoch 00027: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 28/50\n",
      "2323/2323 [==============================] - 1s 595us/step - loss: 0.0737 - matthews_correlation: 0.7359 - val_loss: 0.0894 - val_matthews_correlation: 0.6472\n",
      "\n",
      "Epoch 00028: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 29/50\n",
      "2323/2323 [==============================] - 1s 610us/step - loss: 0.0672 - matthews_correlation: 0.7615 - val_loss: 0.0761 - val_matthews_correlation: 0.7118\n",
      "\n",
      "Epoch 00029: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 30/50\n",
      "2323/2323 [==============================] - 1s 594us/step - loss: 0.0702 - matthews_correlation: 0.7765 - val_loss: 0.0759 - val_matthews_correlation: 0.7143\n",
      "\n",
      "Epoch 00030: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 31/50\n",
      "2323/2323 [==============================] - 1s 598us/step - loss: 0.0855 - matthews_correlation: 0.6359 - val_loss: 0.1377 - val_matthews_correlation: 0.6562\n",
      "\n",
      "Epoch 00031: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 32/50\n",
      "2323/2323 [==============================] - 1s 602us/step - loss: 0.0838 - matthews_correlation: 0.7238 - val_loss: 0.0746 - val_matthews_correlation: 0.7829\n",
      "\n",
      "Epoch 00032: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 33/50\n",
      "2323/2323 [==============================] - 1s 585us/step - loss: 0.0766 - matthews_correlation: 0.7311 - val_loss: 0.0852 - val_matthews_correlation: 0.5932\n",
      "\n",
      "Epoch 00033: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 34/50\n",
      "2323/2323 [==============================] - 1s 580us/step - loss: 0.0684 - matthews_correlation: 0.7147 - val_loss: 0.0830 - val_matthews_correlation: 0.6582\n",
      "\n",
      "Epoch 00034: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 35/50\n",
      "2323/2323 [==============================] - 1s 559us/step - loss: 0.0657 - matthews_correlation: 0.7575 - val_loss: 0.0796 - val_matthews_correlation: 0.7132\n",
      "\n",
      "Epoch 00035: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 36/50\n",
      "2323/2323 [==============================] - 1s 554us/step - loss: 0.0671 - matthews_correlation: 0.7569 - val_loss: 0.0766 - val_matthews_correlation: 0.7620\n",
      "\n",
      "Epoch 00036: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 37/50\n",
      "2323/2323 [==============================] - 1s 561us/step - loss: 0.0649 - matthews_correlation: 0.7708 - val_loss: 0.0836 - val_matthews_correlation: 0.6290\n",
      "\n",
      "Epoch 00037: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 38/50\n",
      "2323/2323 [==============================] - 1s 566us/step - loss: 0.0678 - matthews_correlation: 0.7542 - val_loss: 0.0796 - val_matthews_correlation: 0.7271\n",
      "\n",
      "Epoch 00038: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 39/50\n",
      "2323/2323 [==============================] - 1s 557us/step - loss: 0.0620 - matthews_correlation: 0.7781 - val_loss: 0.0986 - val_matthews_correlation: 0.7374\n",
      "\n",
      "Epoch 00039: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 40/50\n",
      "2323/2323 [==============================] - 1s 562us/step - loss: 0.0720 - matthews_correlation: 0.7647 - val_loss: 0.0870 - val_matthews_correlation: 0.7578\n",
      "\n",
      "Epoch 00040: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 41/50\n",
      "2323/2323 [==============================] - 1s 561us/step - loss: 0.0647 - matthews_correlation: 0.7711 - val_loss: 0.0793 - val_matthews_correlation: 0.7671\n",
      "\n",
      "Epoch 00041: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 42/50\n",
      "2323/2323 [==============================] - 1s 569us/step - loss: 0.0693 - matthews_correlation: 0.7618 - val_loss: 0.0876 - val_matthews_correlation: 0.7293\n",
      "\n",
      "Epoch 00042: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 43/50\n",
      "2323/2323 [==============================] - 1s 590us/step - loss: 0.0617 - matthews_correlation: 0.7974 - val_loss: 0.0852 - val_matthews_correlation: 0.6683\n",
      "\n",
      "Epoch 00043: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 44/50\n",
      "2323/2323 [==============================] - 1s 587us/step - loss: 0.0584 - matthews_correlation: 0.8118 - val_loss: 0.0869 - val_matthews_correlation: 0.6667\n",
      "\n",
      "Epoch 00044: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 45/50\n",
      "2323/2323 [==============================] - 1s 588us/step - loss: 0.0632 - matthews_correlation: 0.7857 - val_loss: 0.1015 - val_matthews_correlation: 0.6020\n",
      "\n",
      "Epoch 00045: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 46/50\n",
      "2323/2323 [==============================] - 1s 591us/step - loss: 0.0601 - matthews_correlation: 0.7902 - val_loss: 0.0764 - val_matthews_correlation: 0.7039\n",
      "\n",
      "Epoch 00046: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 47/50\n",
      "2323/2323 [==============================] - 1s 590us/step - loss: 0.0579 - matthews_correlation: 0.7926 - val_loss: 0.0875 - val_matthews_correlation: 0.7457\n",
      "\n",
      "Epoch 00047: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 48/50\n",
      "2323/2323 [==============================] - 1s 592us/step - loss: 0.0921 - matthews_correlation: 0.6999 - val_loss: 0.1054 - val_matthews_correlation: 0.5842\n",
      "\n",
      "Epoch 00048: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 49/50\n",
      "2323/2323 [==============================] - 1s 593us/step - loss: 0.0827 - matthews_correlation: 0.7043 - val_loss: 0.0717 - val_matthews_correlation: 0.7778\n",
      "\n",
      "Epoch 00049: val_matthews_correlation did not improve from 0.82466\n",
      "Epoch 50/50\n",
      "2323/2323 [==============================] - 1s 589us/step - loss: 0.0700 - matthews_correlation: 0.7910 - val_loss: 0.0913 - val_matthews_correlation: 0.6394\n",
      "\n",
      "Epoch 00050: val_matthews_correlation did not improve from 0.82466\n",
      "Beginning fold 5\n",
      "Train on 2324 samples, validate on 580 samples\n",
      "Epoch 1/50\n",
      "2324/2324 [==============================] - 3s 1ms/step - loss: 0.2929 - matthews_correlation: -0.0011 - val_loss: 0.2073 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_4.h5\n",
      "Epoch 2/50\n",
      "2324/2324 [==============================] - 1s 598us/step - loss: 0.2077 - matthews_correlation: 0.0102 - val_loss: 0.1825 - val_matthews_correlation: 0.1362\n",
      "\n",
      "Epoch 00002: val_matthews_correlation improved from 0.00000 to 0.13616, saving model to weights_4.h5\n",
      "Epoch 3/50\n",
      "2324/2324 [==============================] - 1s 598us/step - loss: 0.1681 - matthews_correlation: 0.2495 - val_loss: 0.1550 - val_matthews_correlation: 0.2634\n",
      "\n",
      "Epoch 00003: val_matthews_correlation improved from 0.13616 to 0.26339, saving model to weights_4.h5\n",
      "Epoch 4/50\n",
      "2324/2324 [==============================] - 1s 600us/step - loss: 0.1311 - matthews_correlation: 0.4530 - val_loss: 0.1369 - val_matthews_correlation: 0.4679\n",
      "\n",
      "Epoch 00004: val_matthews_correlation improved from 0.26339 to 0.46785, saving model to weights_4.h5\n",
      "Epoch 5/50\n",
      "2324/2324 [==============================] - 1s 605us/step - loss: 0.1278 - matthews_correlation: 0.5266 - val_loss: 0.2133 - val_matthews_correlation: 0.4831\n",
      "\n",
      "Epoch 00005: val_matthews_correlation improved from 0.46785 to 0.48312, saving model to weights_4.h5\n",
      "Epoch 6/50\n",
      "2324/2324 [==============================] - 1s 616us/step - loss: 0.1201 - matthews_correlation: 0.5649 - val_loss: 0.1234 - val_matthews_correlation: 0.4540\n",
      "\n",
      "Epoch 00006: val_matthews_correlation did not improve from 0.48312\n",
      "Epoch 7/50\n",
      "2324/2324 [==============================] - 1s 607us/step - loss: 0.1013 - matthews_correlation: 0.6501 - val_loss: 0.1035 - val_matthews_correlation: 0.5993\n",
      "\n",
      "Epoch 00007: val_matthews_correlation improved from 0.48312 to 0.59926, saving model to weights_4.h5\n",
      "Epoch 8/50\n",
      "2324/2324 [==============================] - 1s 604us/step - loss: 0.1027 - matthews_correlation: 0.6923 - val_loss: 0.1087 - val_matthews_correlation: 0.5538\n",
      "\n",
      "Epoch 00008: val_matthews_correlation did not improve from 0.59926\n",
      "Epoch 9/50\n",
      "2324/2324 [==============================] - 1s 602us/step - loss: 0.0971 - matthews_correlation: 0.6379 - val_loss: 0.2832 - val_matthews_correlation: 0.4229\n",
      "\n",
      "Epoch 00009: val_matthews_correlation did not improve from 0.59926\n",
      "Epoch 10/50\n",
      "2324/2324 [==============================] - 1s 601us/step - loss: 0.1334 - matthews_correlation: 0.5712 - val_loss: 0.1026 - val_matthews_correlation: 0.6540\n",
      "\n",
      "Epoch 00010: val_matthews_correlation improved from 0.59926 to 0.65396, saving model to weights_4.h5\n",
      "Epoch 11/50\n",
      "2324/2324 [==============================] - 1s 603us/step - loss: 0.1023 - matthews_correlation: 0.7113 - val_loss: 0.1086 - val_matthews_correlation: 0.5566\n",
      "\n",
      "Epoch 00011: val_matthews_correlation did not improve from 0.65396\n",
      "Epoch 12/50\n",
      "2324/2324 [==============================] - 1s 600us/step - loss: 0.0966 - matthews_correlation: 0.7051 - val_loss: 0.1056 - val_matthews_correlation: 0.5802\n",
      "\n",
      "Epoch 00012: val_matthews_correlation did not improve from 0.65396\n",
      "Epoch 13/50\n",
      "2324/2324 [==============================] - 1s 599us/step - loss: 0.0863 - matthews_correlation: 0.7141 - val_loss: 0.0959 - val_matthews_correlation: 0.5895\n",
      "\n",
      "Epoch 00013: val_matthews_correlation did not improve from 0.65396\n",
      "Epoch 14/50\n",
      "2324/2324 [==============================] - 1s 593us/step - loss: 0.0872 - matthews_correlation: 0.6855 - val_loss: 0.0995 - val_matthews_correlation: 0.6419\n",
      "\n",
      "Epoch 00014: val_matthews_correlation did not improve from 0.65396\n",
      "Epoch 15/50\n",
      "2324/2324 [==============================] - 1s 602us/step - loss: 0.0883 - matthews_correlation: 0.6937 - val_loss: 0.0964 - val_matthews_correlation: 0.5803\n",
      "\n",
      "Epoch 00015: val_matthews_correlation did not improve from 0.65396\n",
      "Epoch 16/50\n",
      "2324/2324 [==============================] - 1s 600us/step - loss: 0.0795 - matthews_correlation: 0.7358 - val_loss: 0.0934 - val_matthews_correlation: 0.6420\n",
      "\n",
      "Epoch 00016: val_matthews_correlation did not improve from 0.65396\n",
      "Epoch 17/50\n",
      "2324/2324 [==============================] - 1s 603us/step - loss: 0.0768 - matthews_correlation: 0.7585 - val_loss: 0.0888 - val_matthews_correlation: 0.6479\n",
      "\n",
      "Epoch 00017: val_matthews_correlation did not improve from 0.65396\n",
      "Epoch 18/50\n",
      "2324/2324 [==============================] - 1s 597us/step - loss: 0.0710 - matthews_correlation: 0.7806 - val_loss: 0.1625 - val_matthews_correlation: 0.5889\n",
      "\n",
      "Epoch 00018: val_matthews_correlation did not improve from 0.65396\n",
      "Epoch 19/50\n",
      "2324/2324 [==============================] - 1s 602us/step - loss: 0.0901 - matthews_correlation: 0.7432 - val_loss: 0.0992 - val_matthews_correlation: 0.5897\n",
      "\n",
      "Epoch 00019: val_matthews_correlation did not improve from 0.65396\n",
      "Epoch 20/50\n",
      "2324/2324 [==============================] - 1s 597us/step - loss: 0.0884 - matthews_correlation: 0.6922 - val_loss: 0.0983 - val_matthews_correlation: 0.6098\n",
      "\n",
      "Epoch 00020: val_matthews_correlation did not improve from 0.65396\n",
      "Epoch 21/50\n",
      "2324/2324 [==============================] - 1s 602us/step - loss: 0.0834 - matthews_correlation: 0.7118 - val_loss: 0.0987 - val_matthews_correlation: 0.6573\n",
      "\n",
      "Epoch 00021: val_matthews_correlation improved from 0.65396 to 0.65731, saving model to weights_4.h5\n",
      "Epoch 22/50\n",
      "2324/2324 [==============================] - 1s 605us/step - loss: 0.0738 - matthews_correlation: 0.7866 - val_loss: 0.1141 - val_matthews_correlation: 0.5361\n",
      "\n",
      "Epoch 00022: val_matthews_correlation did not improve from 0.65731\n",
      "Epoch 23/50\n",
      "2324/2324 [==============================] - 1s 599us/step - loss: 0.0847 - matthews_correlation: 0.7349 - val_loss: 0.0848 - val_matthews_correlation: 0.6754\n",
      "\n",
      "Epoch 00023: val_matthews_correlation improved from 0.65731 to 0.67541, saving model to weights_4.h5\n",
      "Epoch 24/50\n",
      "2324/2324 [==============================] - 1s 595us/step - loss: 0.0735 - matthews_correlation: 0.7266 - val_loss: 0.0969 - val_matthews_correlation: 0.7031\n",
      "\n",
      "Epoch 00024: val_matthews_correlation improved from 0.67541 to 0.70315, saving model to weights_4.h5\n",
      "Epoch 25/50\n",
      "2324/2324 [==============================] - 1s 600us/step - loss: 0.0702 - matthews_correlation: 0.7501 - val_loss: 0.1626 - val_matthews_correlation: 0.5792\n",
      "\n",
      "Epoch 00025: val_matthews_correlation did not improve from 0.70315\n",
      "Epoch 26/50\n",
      "2324/2324 [==============================] - 1s 602us/step - loss: 0.0899 - matthews_correlation: 0.6865 - val_loss: 0.0971 - val_matthews_correlation: 0.5946\n",
      "\n",
      "Epoch 00026: val_matthews_correlation did not improve from 0.70315\n",
      "Epoch 27/50\n",
      "2324/2324 [==============================] - 1s 600us/step - loss: 0.0775 - matthews_correlation: 0.7481 - val_loss: 0.0890 - val_matthews_correlation: 0.7173\n",
      "\n",
      "Epoch 00027: val_matthews_correlation improved from 0.70315 to 0.71729, saving model to weights_4.h5\n",
      "Epoch 28/50\n",
      "2324/2324 [==============================] - 1s 600us/step - loss: 0.0730 - matthews_correlation: 0.7100 - val_loss: 0.0982 - val_matthews_correlation: 0.6976\n",
      "\n",
      "Epoch 00028: val_matthews_correlation did not improve from 0.71729\n",
      "Epoch 29/50\n",
      "2324/2324 [==============================] - 1s 598us/step - loss: 0.0689 - matthews_correlation: 0.7595 - val_loss: 0.1244 - val_matthews_correlation: 0.6467\n",
      "\n",
      "Epoch 00029: val_matthews_correlation did not improve from 0.71729\n",
      "Epoch 30/50\n",
      "2324/2324 [==============================] - 1s 603us/step - loss: 0.0806 - matthews_correlation: 0.7109 - val_loss: 0.1004 - val_matthews_correlation: 0.7035\n",
      "\n",
      "Epoch 00030: val_matthews_correlation did not improve from 0.71729\n",
      "Epoch 31/50\n",
      "2324/2324 [==============================] - 1s 600us/step - loss: 0.0689 - matthews_correlation: 0.7603 - val_loss: 0.1021 - val_matthews_correlation: 0.5818\n",
      "\n",
      "Epoch 00031: val_matthews_correlation did not improve from 0.71729\n",
      "Epoch 32/50\n",
      "2324/2324 [==============================] - 1s 600us/step - loss: 0.0614 - matthews_correlation: 0.7849 - val_loss: 0.1082 - val_matthews_correlation: 0.7025\n",
      "\n",
      "Epoch 00032: val_matthews_correlation did not improve from 0.71729\n",
      "Epoch 33/50\n",
      "2324/2324 [==============================] - 1s 601us/step - loss: 0.0680 - matthews_correlation: 0.7688 - val_loss: 0.0905 - val_matthews_correlation: 0.6143\n",
      "\n",
      "Epoch 00033: val_matthews_correlation did not improve from 0.71729\n",
      "Epoch 34/50\n",
      "2324/2324 [==============================] - 1s 598us/step - loss: 0.0649 - matthews_correlation: 0.7615 - val_loss: 0.0933 - val_matthews_correlation: 0.6741\n",
      "\n",
      "Epoch 00034: val_matthews_correlation did not improve from 0.71729\n",
      "Epoch 35/50\n",
      "2324/2324 [==============================] - 1s 602us/step - loss: 0.0694 - matthews_correlation: 0.7329 - val_loss: 0.0969 - val_matthews_correlation: 0.7029\n",
      "\n",
      "Epoch 00035: val_matthews_correlation did not improve from 0.71729\n",
      "Epoch 36/50\n",
      "2324/2324 [==============================] - 1s 599us/step - loss: 0.0623 - matthews_correlation: 0.7731 - val_loss: 0.0957 - val_matthews_correlation: 0.6949\n",
      "\n",
      "Epoch 00036: val_matthews_correlation did not improve from 0.71729\n",
      "Epoch 37/50\n",
      "2324/2324 [==============================] - 1s 601us/step - loss: 0.0717 - matthews_correlation: 0.7606 - val_loss: 0.0988 - val_matthews_correlation: 0.5678\n",
      "\n",
      "Epoch 00037: val_matthews_correlation did not improve from 0.71729\n",
      "Epoch 38/50\n",
      "2324/2324 [==============================] - 1s 603us/step - loss: 0.0733 - matthews_correlation: 0.7525 - val_loss: 0.1182 - val_matthews_correlation: 0.6645\n",
      "\n",
      "Epoch 00038: val_matthews_correlation did not improve from 0.71729\n",
      "Epoch 39/50\n",
      "2324/2324 [==============================] - 1s 605us/step - loss: 0.0776 - matthews_correlation: 0.7489 - val_loss: 0.0943 - val_matthews_correlation: 0.6048\n",
      "\n",
      "Epoch 00039: val_matthews_correlation did not improve from 0.71729\n",
      "Epoch 40/50\n",
      "2324/2324 [==============================] - 1s 600us/step - loss: 0.0737 - matthews_correlation: 0.7684 - val_loss: 0.0900 - val_matthews_correlation: 0.6187\n",
      "\n",
      "Epoch 00040: val_matthews_correlation did not improve from 0.71729\n",
      "Epoch 41/50\n",
      "2324/2324 [==============================] - 1s 603us/step - loss: 0.0686 - matthews_correlation: 0.8059 - val_loss: 0.0920 - val_matthews_correlation: 0.6612\n",
      "\n",
      "Epoch 00041: val_matthews_correlation did not improve from 0.71729\n",
      "Epoch 42/50\n",
      "2324/2324 [==============================] - 1s 600us/step - loss: 0.0783 - matthews_correlation: 0.7320 - val_loss: 0.0910 - val_matthews_correlation: 0.7039\n",
      "\n",
      "Epoch 00042: val_matthews_correlation did not improve from 0.71729\n",
      "Epoch 43/50\n",
      "2324/2324 [==============================] - 1s 601us/step - loss: 0.0680 - matthews_correlation: 0.7988 - val_loss: 0.1076 - val_matthews_correlation: 0.5976\n",
      "\n",
      "Epoch 00043: val_matthews_correlation did not improve from 0.71729\n",
      "Epoch 44/50\n",
      "2324/2324 [==============================] - 1s 607us/step - loss: 0.0638 - matthews_correlation: 0.7583 - val_loss: 0.0883 - val_matthews_correlation: 0.6649\n",
      "\n",
      "Epoch 00044: val_matthews_correlation did not improve from 0.71729\n",
      "Epoch 45/50\n",
      "2324/2324 [==============================] - 1s 598us/step - loss: 0.0631 - matthews_correlation: 0.7854 - val_loss: 0.0872 - val_matthews_correlation: 0.7225\n",
      "\n",
      "Epoch 00045: val_matthews_correlation improved from 0.71729 to 0.72250, saving model to weights_4.h5\n",
      "Epoch 46/50\n",
      "2324/2324 [==============================] - 1s 602us/step - loss: 0.0618 - matthews_correlation: 0.7940 - val_loss: 0.0954 - val_matthews_correlation: 0.6239\n",
      "\n",
      "Epoch 00046: val_matthews_correlation did not improve from 0.72250\n",
      "Epoch 47/50\n",
      "2324/2324 [==============================] - 1s 625us/step - loss: 0.0685 - matthews_correlation: 0.7841 - val_loss: 0.1113 - val_matthews_correlation: 0.5514\n",
      "\n",
      "Epoch 00047: val_matthews_correlation did not improve from 0.72250\n",
      "Epoch 48/50\n",
      "2324/2324 [==============================] - 1s 609us/step - loss: 0.0807 - matthews_correlation: 0.7307 - val_loss: 0.1091 - val_matthews_correlation: 0.6491\n",
      "\n",
      "Epoch 00048: val_matthews_correlation did not improve from 0.72250\n",
      "Epoch 49/50\n",
      "2324/2324 [==============================] - 1s 626us/step - loss: 0.0679 - matthews_correlation: 0.7830 - val_loss: 0.0881 - val_matthews_correlation: 0.6890\n",
      "\n",
      "Epoch 00049: val_matthews_correlation did not improve from 0.72250\n",
      "Epoch 50/50\n",
      "2324/2324 [==============================] - 1s 601us/step - loss: 0.0659 - matthews_correlation: 0.7673 - val_loss: 0.1067 - val_matthews_correlation: 0.6688\n",
      "\n",
      "Epoch 00050: val_matthews_correlation did not improve from 0.72250\n",
      "(2904, 3) (2904, 3)\n",
      "CPU times: user 5min 49s, sys: 56.8 s, total: 6min 45s\n",
      "Wall time: 6min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(splits):\n",
    "    K.clear_session() # I dont know what it do, but I imagine that it \"clear session\" :)\n",
    "    print(\"Beginning fold {}\".format(idx+1))\n",
    "    cal_list.append(val_idx)\n",
    "    # use the indexes to extract the folds in the train and validation data\n",
    "    train_X, train_y, val_X, val_y = X[train_idx], y[train_idx], X[val_idx], y[val_idx]\n",
    "    # instantiate the model for this fold\n",
    "    model = model_lstm(train_X.shape)\n",
    "    # This checkpoint helps to avoid overfitting. It just save the weights of the model if it delivered an\n",
    "    # validation matthews_correlation greater than the last one.\n",
    "    ckpt = ModelCheckpoint('weights_{}.h5'.format(idx), save_best_only=True, save_weights_only=True, verbose=1, monitor='val_matthews_correlation', mode='max')\n",
    "    # Train, train, train\n",
    "    model.fit(train_X, train_y, batch_size=128, epochs=50, validation_data=[val_X, val_y], callbacks=[ckpt])\n",
    "    # loads the best weights saved by the checkpoint\n",
    "    model.load_weights('weights_{}.h5'.format(idx))\n",
    "    # Add the predictions of the validation to the list preds_val\n",
    "    preds_val.append(model.predict(val_X, batch_size=512))\n",
    "    # and the val true y\n",
    "    y_val.append(val_y)\n",
    "\n",
    "# concatenates all and prints the shape    \n",
    "preds_val = np.concatenate(preds_val)\n",
    "y_val = np.concatenate(y_val)\n",
    "cal_list=np.concatenate(cal_list)\n",
    "print(preds_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "d28151fd0be9fd9762f3f55e307d82f89bfbd291"
   },
   "outputs": [],
   "source": [
    "# The output of this kernel must be binary (0 or 1), but the output of the NN Model is float (0 to 1).\n",
    "# So, find the best threshold to convert float to binary is crucial to the result\n",
    "# this piece of code is a function that evaluates all the possible thresholds from 0 to 1 by 0.01\n",
    "\n",
    "def threshold_search(y_true, y_proba):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in tqdm([i * 0.01 for i in range(100)]):\n",
    "        score = K.eval(matthews_correlation(K.variable(y_true), K.variable((y_proba > threshold).astype(np.int))))\n",
    "        if score > best_score:\n",
    "            best_threshold = threshold\n",
    "            best_score = score\n",
    "    print(best_threshold,best_score)\n",
    "    search_result = {'threshold': best_threshold, 'matthews_correlation': best_score}\n",
    "    \n",
    "    return search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "6fee7f722ed08bc1453a822a4371ed2d48e08abc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:54<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49 0.7293547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_threshold = threshold_search(y_val,preds_val)['threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "58f80c0b77191c4d0f1765485da3679f01ac9ace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 [1 1 1] [0 0 0]\n",
      "76 [0 0 0] [1 1 1]\n",
      "88 [1 1 1] [0 0 0]\n",
      "235 [0 0 0] [1 1 1]\n",
      "271 [0 0 0] [1 0 0]\n",
      "276 [1 1 1] [0 0 0]\n",
      "443 [1 1 1] [0 0 1]\n",
      "620 [1 1 1] [1 0 1]\n",
      "695 [1 0 1] [1 1 1]\n",
      "699 [0 0 0] [1 1 1]\n",
      "962 [1 0 1] [0 0 0]\n",
      "988 [1 1 1] [0 1 1]\n",
      "1010 [0 0 0] [1 1 1]\n",
      "1076 [1 1 1] [1 1 0]\n",
      "1081 [0 0 0] [1 1 1]\n",
      "1132 [1 1 1] [1 0 0]\n",
      "1310 [1 1 1] [0 0 0]\n",
      "1537 [1 1 1] [1 0 1]\n",
      "1680 [1 1 0] [0 0 0]\n",
      "1810 [1 1 1] [0 0 0]\n",
      "1855 [1 1 1] [0 0 0]\n",
      "1884 [1 1 1] [0 0 1]\n",
      "1897 [1 1 1] [0 0 0]\n",
      "1899 [1 1 1] [0 0 1]\n",
      "1965 [1 1 1] [0 0 0]\n",
      "2090 [1 1 1] [0 0 0]\n",
      "2126 [1 0 1] [1 1 1]\n",
      "2212 [0 0 0] [1 1 1]\n",
      "2623 [1 1 1] [1 1 0]\n",
      "2688 [1 1 1] [0 0 0]\n",
      "2702 [1 1 1] [0 0 0]\n",
      "2876 [0 0 0] [0 0 1]\n",
      "41 [1 1 1] [0 0 0]\n",
      "90 [0 0 0] [1 1 1]\n",
      "96 [1 1 1] [0 0 1]\n",
      "145 [0 0 0] [1 1 1]\n",
      "608 [0 0 0] [1 0 1]\n",
      "706 [1 1 1] [1 1 0]\n",
      "809 [1 0 1] [0 0 0]\n",
      "894 [1 1 1] [1 0 0]\n",
      "900 [1 1 1] [0 0 0]\n",
      "923 [1 1 1] [0 0 0]\n",
      "1055 [1 1 0] [0 0 0]\n",
      "1103 [0 0 0] [1 1 1]\n",
      "1256 [1 1 1] [1 0 1]\n",
      "1277 [1 0 1] [1 0 0]\n",
      "1442 [1 1 1] [0 0 0]\n",
      "1476 [1 1 1] [0 0 0]\n",
      "1549 [1 1 1] [0 0 0]\n",
      "1561 [0 0 0] [0 0 1]\n",
      "1624 [0 0 0] [1 1 1]\n",
      "1675 [1 1 1] [0 0 0]\n",
      "1769 [0 0 0] [1 1 1]\n",
      "2087 [1 1 1] [0 0 0]\n",
      "2671 [1 1 1] [0 0 0]\n",
      "67 [1 1 1] [1 1 0]\n",
      "308 [1 1 1] [0 0 0]\n",
      "444 [1 1 1] [0 0 0]\n",
      "579 [0 0 0] [1 1 1]\n",
      "633 [0 0 0] [1 1 1]\n",
      "737 [1 1 1] [0 0 0]\n",
      "774 [0 0 0] [1 1 1]\n",
      "785 [1 1 1] [0 0 0]\n",
      "830 [1 1 1] [0 0 0]\n",
      "838 [0 0 0] [1 1 1]\n",
      "984 [0 0 0] [1 1 1]\n",
      "1091 [1 1 1] [0 0 1]\n",
      "1268 [0 0 0] [0 0 1]\n",
      "1326 [0 0 0] [1 1 1]\n",
      "1351 [1 0 1] [1 1 1]\n",
      "1405 [1 1 1] [0 0 0]\n",
      "1424 [1 1 1] [0 0 0]\n",
      "1589 [0 0 0] [1 1 1]\n",
      "1646 [0 0 0] [1 1 1]\n",
      "1669 [0 0 0] [1 1 1]\n",
      "1687 [1 0 1] [1 1 1]\n",
      "2094 [1 0 1] [1 1 1]\n",
      "2677 [0 0 0] [1 1 1]\n",
      "2753 [1 0 1] [0 0 1]\n",
      "2823 [1 1 1] [0 0 0]\n",
      "126 [0 0 0] [0 0 1]\n",
      "295 [1 1 1] [0 0 0]\n",
      "301 [1 1 1] [1 0 0]\n",
      "518 [0 0 0] [1 0 0]\n",
      "601 [1 1 1] [1 0 1]\n",
      "870 [1 1 1] [0 0 0]\n",
      "876 [0 0 0] [1 1 1]\n",
      "944 [1 1 1] [0 1 1]\n",
      "1068 [1 1 1] [1 0 1]\n",
      "1386 [0 0 0] [1 1 1]\n",
      "1637 [1 1 1] [0 0 0]\n",
      "1761 [0 0 0] [1 1 1]\n",
      "2322 [0 0 0] [1 1 1]\n",
      "2328 [1 1 1] [1 0 1]\n",
      "2693 [1 1 1] [1 0 1]\n",
      "2797 [1 1 0] [0 0 0]\n",
      "2807 [0 0 0] [0 1 1]\n",
      "159 [0 0 0] [0 0 1]\n",
      "190 [0 0 0] [1 1 1]\n",
      "233 [0 0 0] [1 1 1]\n",
      "292 [1 0 1] [1 1 1]\n",
      "720 [0 0 0] [1 1 1]\n",
      "1037 [1 1 1] [0 0 0]\n",
      "1381 [0 0 0] [1 1 1]\n",
      "1420 [0 0 0] [0 0 1]\n",
      "1668 [0 0 0] [1 0 1]\n",
      "1704 [0 0 0] [1 1 0]\n",
      "1981 [0 0 0] [1 1 1]\n",
      "1994 [1 1 1] [0 1 0]\n",
      "2015 [1 1 1] [0 0 0]\n",
      "2060 [1 1 1] [0 0 0]\n",
      "2099 [1 1 1] [0 0 0]\n",
      "2340 [0 0 0] [1 1 1]\n",
      "2548 [1 0 0] [1 1 1]\n",
      "2760 [0 0 0] [1 1 0]\n",
      "2779 [1 1 1] [0 0 0]\n",
      "2811 [1 0 1] [1 1 1]\n",
      "2856 [0 0 0] [1 1 1]\n",
      "[13, 76, 88, 235, 271, 276, 443, 620, 695, 699, 962, 988, 1010, 1076, 1081, 1132, 1310, 1537, 1680, 1810, 1855, 1884, 1897, 1899, 1965, 2090, 2126, 2212, 2623, 2688, 2702, 2876, 41, 90, 96, 145, 608, 706, 809, 894, 900, 923, 1055, 1103, 1256, 1277, 1442, 1476, 1549, 1561, 1624, 1675, 1769, 2087, 2671, 67, 308, 444, 579, 633, 737, 774, 785, 830, 838, 984, 1091, 1268, 1326, 1351, 1405, 1424, 1589, 1646, 1669, 1687, 2094, 2677, 2753, 2823, 126, 295, 301, 518, 601, 870, 876, 944, 1068, 1386, 1637, 1761, 2322, 2328, 2693, 2797, 2807, 159, 190, 233, 292, 720, 1037, 1381, 1420, 1668, 1704, 1981, 1994, 2015, 2060, 2099, 2340, 2548, 2760, 2779, 2811, 2856]\n"
     ]
    }
   ],
   "source": [
    "wrongpred = []\n",
    "preds_val = (preds_val > best_threshold).astype(np.int)\n",
    "for i,y in enumerate(y_val):\n",
    "    if (preds_val[i]!= y).any():\n",
    "        print(cal_list[i],preds_val[i],y)\n",
    "        wrongpred.append(cal_list[i])\n",
    "print(wrongpred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "3eb186d032f79c99ffba05dd1a7fabb77e13cec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32 ms, sys: 8 ms, total: 40 ms\n",
      "Wall time: 26.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Now load the test data\n",
    "# This first part is the meta data, not the main data, the measurements\n",
    "meta_test = pd.read_csv('../input/metadata_test.csv')\n",
    "meta_test = meta_test.set_index(['id_measurement', 'phase'])\n",
    "meta_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "efa6ef5b2659b0a295343e728d2d9d89c1a0ff9c"
   },
   "outputs": [],
   "source": [
    "meta_test['target']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "456ebd66ed044db62b49a3fe0626fc847f2d05c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_measurement</th>\n",
       "      <th>phase</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2904</th>\n",
       "      <th>0</th>\n",
       "      <td>8712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2905</th>\n",
       "      <th>0</th>\n",
       "      <td>8715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      signal_id  target\n",
       "id_measurement phase                   \n",
       "2904           0           8712       0\n",
       "               1           8713       0\n",
       "               2           8714       0\n",
       "2905           0           8715       0\n",
       "               1           8716       0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "caaa9761b19076011179df9760659801acbcc2fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_measurement</th>\n",
       "      <th>phase</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">9681</th>\n",
       "      <th>1</th>\n",
       "      <td>29044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">9682</th>\n",
       "      <th>0</th>\n",
       "      <td>29046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      signal_id  target\n",
       "id_measurement phase                   \n",
       "9681           1          29044       0\n",
       "               2          29045       0\n",
       "9682           0          29046       0\n",
       "               1          29047       0\n",
       "               2          29048       0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "1512b3d9f123221beafff09420ca68443c8c7f99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2904 9683\n",
      "[2904, 3581]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1/11 [10:57<1:49:35, 657.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(677, 160, 162) (677, 3)\n",
      "[3581, 4258]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 2/11 [21:49<1:38:23, 655.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(677, 160, 162) (677, 3)\n",
      "[4258, 4935]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3/11 [32:37<1:27:06, 653.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(677, 160, 162) (677, 3)\n",
      "[4935, 5612]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4/11 [43:26<1:16:05, 652.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(677, 160, 162) (677, 3)\n",
      "[5612, 6289]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 5/11 [54:17<1:05:10, 651.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(677, 160, 162) (677, 3)\n",
      "[6289, 6966]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 6/11 [1:05:07<54:17, 651.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(677, 160, 162) (677, 3)\n",
      "[6966, 7643]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 7/11 [1:15:56<43:22, 650.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(677, 160, 162) (677, 3)\n",
      "[7643, 8320]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 8/11 [1:26:40<32:25, 648.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(677, 160, 162) (677, 3)\n",
      "[8320, 8997]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 9/11 [1:37:27<21:36, 648.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(677, 160, 162) (677, 3)\n",
      "[8997, 9674]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 10/11 [1:48:15<10:48, 648.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(677, 160, 162) (677, 3)\n",
      "[9674, 9683]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [1:48:25<00:00, 456.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 160, 162) (9, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6779, 160, 162)\n",
      "CPU times: user 1h 47min 59s, sys: 24.8 s, total: 1h 48min 24s\n",
      "Wall time: 1h 48min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test,y_test = load_all(meta_test,'../input/test.parquet',10)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "cfd265d3e07c4cc1679d2c4d55fe7de631c813e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20337\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   signal_id  target\n",
       "0       8712       0\n",
       "1       8713       0\n",
       "2       8714       0\n",
       "3       8715       0\n",
       "4       8716       0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "print(len(submission))\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "2f7342296138f6bfd3e9cedd029e1035de3b98fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6779/6779 [==============================] - 3s 442us/step\n",
      "(6779, 3)\n",
      "6779/6779 [==============================] - 3s 451us/step\n",
      "(6779, 3)\n",
      "6779/6779 [==============================] - 3s 449us/step\n",
      "(6779, 3)\n",
      "6779/6779 [==============================] - 3s 447us/step\n",
      "(6779, 3)\n",
      "6779/6779 [==============================] - 3s 449us/step\n",
      "(6779, 3)\n",
      "(5, 6779, 3)\n"
     ]
    }
   ],
   "source": [
    "preds_test = []\n",
    "for i in range(N_SPLITS):\n",
    "    model.load_weights('weights_{}.h5'.format(i))\n",
    "    pred = model.predict(X_test, batch_size=300, verbose=1)\n",
    "    print(pred.shape)\n",
    "    preds_test.append(pred)\n",
    "print(np.asarray(preds_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "9f76c471eaf983707d446c5081ab3d50c4e40ea5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20337,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test = (np.mean(preds_test, axis=0).reshape(-1) > best_threshold).astype(np.int)\n",
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "4220ff3807695eddc452a70a8278e2613852c681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(preds_test[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "b35723f85d494b4b6ec630dd7c79135a110a4062"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   signal_id  target\n",
       "0       8712       0\n",
       "1       8713       0\n",
       "2       8714       0\n",
       "3       8715       0\n",
       "4       8716       0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['target'] = preds_test\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "d7600d0093a9880003240ef9ce0a1f1303e4d982"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
